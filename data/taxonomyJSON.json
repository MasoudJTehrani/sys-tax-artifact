[
  {
    "Ref":"[1]",
    "Paper Title":"SlowTrack: Increasing the latency of camera-based perception in autonomous driving using adversarial examples",
    "App Domain":"Cars",
    "DL Model Under Attack":"SORT(Y5), FairMOT, ByteTrack, BoT-SORT (Perception)",
    "System Under attack":"Baidu Apollo in LGSVL simulator (MSF)",
    "Attack Scenario":"AVs changing lanes when another car is in the adjacent lane or approaching an intersection with a stop sign where another car is present",
    "Attacked Target":"Input image",
    "Attacker's Capability":"Purturbing the image input to insert fake bounding boxes into it",
    "Attack Strategy":"Evasion",
    "Attacker's System\/Model knowledge":"WM \/ BS",
    "Attack\/Error Specificity":"AG \/ EG",
    "Failure Specificity":"Generic",
    "Model-level results":"Losing detection and subsequently tracking of the target object",
    "System-level results (Failure Propagation)":"Crashing into another car"
  },
  {
    "Ref":"[2]",
    "Paper Title":"RPAU: Fooling the eyes of UAVs via physical adversarial patches",
    "App Domain":"Drones",
    "DL Model Under Attack":"A variation of DroNet (E2E)",
    "System Under attack":"Parrot Bebop 2 Drone and Matlab simulation (SSF)",
    "Attack Scenario":"Drones moving to its destination",
    "Attacked Target":"Environment (anything that can hold a patch horizontally)",
    "Attacker's Capability":"Attaching the patch to anything that can hold it horizontally, facing the drone.",
    "Attack Strategy":"Evasion",
    "Attacker's System\/Model knowledge":"WM \/ GS",
    "Attack\/Error Specificity":"AG \/ ES",
    "Failure Specificity":"Specific",
    "Model-level results":"Misdetection of objects and Misprediction of the steering wheel angle",
    "System-level results (Failure Propagation)":"Crashing to objects, freezing or going off-route"
  },
  {
    "Ref":"[3]",
    "Paper Title":"Adversarial attacks on adaptive cruise control systems",
    "App Domain":"Cars",
    "DL Model Under Attack":"OpenPilot's Adaptive Cruise Control ACC system (Perception)",
    "System Under attack":"CARLA and Baidu Apollo (MSF)",
    "Attack Scenario":"AV driving behind the attacker's vehicle",
    "Attacked Target":"Vehicles and Trucks",
    "Attacker's Capability":"Placing the patch on the back of a vehicle and drive it in front of the AV",
    "Attack Strategy":"Evasion",
    "Attacker's System\/Model knowledge":"WM \/ BS",
    "Attack\/Error Specificity":"AS \/ ES",
    "Failure Specificity":"Specific",
    "Model-level results":"Misdetection of the vehicle in front",
    "System-level results (Failure Propagation)":"Acceleration and crash into the car in front"
  },
  {
    "Ref":"[4]",
    "Paper Title":"Learning when to use adaptive adversarial image perturbations against autonomous vehicles",
    "App Domain":"Cars, Drones",
    "DL Model Under Attack":"YOLO v5 (Perception)",
    "System Under attack":"Vision-based guidance system in CARLA or AirSim (SSF)",
    "Attack Scenario":"AVs following their target",
    "Attacked Target":"Input image",
    "Attacker's Capability":"Inserting the malware into the system and training the perturbations on the real training set",
    "Attack Strategy":"Evasion",
    "Attacker's System\/Model knowledge":"WM \/ BS",
    "Attack\/Error Specificity":"AG \/ EG",
    "Failure Specificity":"Generic",
    "Model-level results":"Misdetection of the correct coordinates of the target bounding box",
    "System-level results (Failure Propagation)":"Losing path, stability and collision to surrounding obstacles"
  },
  {
    "Ref":"[5]",
    "Paper Title":"DeepManeuver: Adversarial test generation for trajectory manipulation of autonomous vehicles",
    "App Domain":"Cars",
    "DL Model Under Attack":"Dave2 (E2E)",
    "System Under attack":"An AV vehicle (hopper vehicle) in BeamNG (SSF)",
    "Attack Scenario":"AVs driving past a roadside billboard.",
    "Attacked Target":"Billboards (placing their own malicious billboard)",
    "Attacker's Capability":"Installing a perturbed billboard or altering an existing one",
    "Attack Strategy":"Evasion",
    "Attacker's System\/Model knowledge":"WM \/ BS",
    "Attack\/Error Specificity":"AS \/ EG",
    "Failure Specificity":"Generic",
    "Model-level results":"Misprediction of the steering wheel angle",
    "System-level results (Failure Propagation)":"Going off-road"
  },
  {
    "Ref":"[6]",
    "Paper Title":"Kidnapping deep learning-based multirotors using optimized flying adversarial patches",
    "App Domain":"Drones",
    "DL Model Under Attack":"PULP Frontnet (Perception)",
    "System Under attack":"A human-following drone control system known as the nano multirotor, the Crazyflie by Bitcraze. (SSF)",
    "Attack Scenario":"Autonomous drones following a human target",
    "Attacked Target":"Input image",
    "Attacker's Capability":"Moving a printed patch in front of a drone",
    "Attack Strategy":"Evasion",
    "Attacker's System\/Model knowledge":"WM \/ BS",
    "Attack\/Error Specificity":"AG \/ ES",
    "Failure Specificity":"Specific",
    "Model-level results":"Misclassification of the adversarial patch as a real human",
    "System-level results (Failure Propagation)":"Following the adversarially patched image and failing to detect the real human"
  },
  {
    "Ref":"[7]",
    "Paper Title":"Does physical adversarial example really matter to autonomous driving?",
    "App Domain":"Cars",
    "DL Model Under Attack":"YOLO v2, v3, v5 (Perception)",
    "System Under attack":"Baidu Apollo in LGSVL simulator (MSF)",
    "Attack Scenario":"AVs approaching a critical physical road object on a sunny day, such as a stop sign or pedestrian",
    "Attacked Target":"Stop signs and pedestrians",
    "Attacker's Capability":"Attaching adversarial patches on stop signs or pedestrians' shirts.",
    "Attack Strategy":"Evasion",
    "Attacker's System\/Model knowledge":"WM \/ BS",
    "Attack\/Error Specificity":"AS \/ ES",
    "Failure Specificity":"Specific",
    "Model-level results":"Failure to detect stop signs and pedestrians",
    "System-level results (Failure Propagation)":"Running a stop sign and colliding with pedestrians"
  },
  {
    "Ref":"[8]",
    "Paper Title":"On data fabrication in collaborative vehicular perception: Attacks and countermeasures",
    "App Domain":"Cars",
    "DL Model Under Attack":"PointPillars, VoxelNet, V2VNet, CoBEVT, FPV-RCNN (Perception)",
    "System Under attack":"AVs utilizing LiDAR or GPS information from other cars in Baidu Apollo (MSF)",
    "Attack Scenario":"Multiple AVs driving and jointly performing collaborative perception tasks",
    "Attacked Target":"Objects in the shared feature map",
    "Attacker's Capability":"Manipulating shared LiDAR vision data by spoofing or removing objects from it",
    "Attack Strategy":"Evasion",
    "Attacker's System\/Model knowledge":"WM & BM \/ GS",
    "Attack\/Error Specificity":"AS \/ ES",
    "Failure Specificity":"Specific",
    "Model-level results":"Detecting fake objects as real while failing to detect a real object",
    "System-level results (Failure Propagation)":"Stopping unexpectedly or causing collisions with objects"
  },
  {
    "Ref":"[9]",
    "Paper Title":"Rolling colors: Adversarial laser exploits against traffic light recognition",
    "App Domain":"Cars",
    "DL Model Under Attack":"Nexar & YOLO v4 (Perception)",
    "System Under attack":"Baidu Apollo in LGSVL simulator (MSF)",
    "Attack Scenario":"AVs approaching a traffic light",
    "Attacked Target":"Camera",
    "Attacker's Capability":"Directing a laser beam towards the camera of the victim",
    "Attack Strategy":"Evasion",
    "Attacker's System\/Model knowledge":"WM \/ BS",
    "Attack\/Error Specificity":"AS \/ ES",
    "Failure Specificity":"Specific",
    "Model-level results":"Misclassification of traffic light colors",
    "System-level results (Failure Propagation)":"Running a red light, causing a car crash or emergency stop, which leads to the vehicle freezing"
  },
  {
    "Ref":"[10]",
    "Paper Title":"Stop-and-go: Exploring backdoor attacks on deep reinforcement learning-based traffic congestion control systems",
    "App Domain":"Cars",
    "DL Model Under Attack":"DRL in decision-making module of SUMO (Planning)",
    "System Under attack":"Microscopic traffic simulator SUMO And intelligent driver model (SSF)",
    "Attack Scenario":"AVs driving in one or two lanes, following the malicious leading vehicle in traffic",
    "Attacked Target":"Training data",
    "Attacker's Capability":"Injecting a backdoor into the model by retraining it with poisoned data.",
    "Attack Strategy":"Poisoning",
    "Attacker's System\/Model knowledge":"WM \/ BS",
    "Attack\/Error Specificity":"AS \/ ES",
    "Failure Specificity":"Specific",
    "Model-level results":"Failing to predict the correct reaction to traffic.",
    "System-level results (Failure Propagation)":"Causing a collision with the car in front"
  },
  {
    "Ref":"[11]",
    "Paper Title":"Attack and fault injection in self-driving agents on the CARLA simulator \u2013 experience report",
    "App Domain":"Cars",
    "DL Model Under Attack":"ResNet-34 (E2E)",
    "System Under attack":"Learning by cheating agent in CARLA (SSF)",
    "Attack Scenario":"AVs on a road with pedestrians and other vehicles",
    "Attacked Target":"Input image",
    "Attacker's Capability":"Manipulating the neurons and weights of the NN, or manipulating input images",
    "Attack Strategy":"Evasion",
    "Attacker's System\/Model knowledge":"WM & BM \/ BS",
    "Attack\/Error Specificity":"AG \/ EG",
    "Failure Specificity":"Specific",
    "Model-level results":"Misprediction of the steering wheel angle and failure to detect traffic lights",
    "System-level results (Failure Propagation)":"Losing lane, going offroad, crashing into buildings, ignoring traffic lights, going to crossroads"
  },
  {
    "Ref":"[12]",
    "Paper Title":"Dirty road can attack: Security of deep learning based automated lane centering under Physical-World attack",
    "App Domain":"Cars",
    "DL Model Under Attack":"OpenPilot's Automated Lane Centering (ALC) (E2E)",
    "System Under attack":"Automated Lane Centering (ALC) system in LGSVL (SSF)",
    "Attack Scenario":"AVs driving",
    "Attacked Target":"Roads",
    "Attacker's Capability":"Placing patches on the road surface",
    "Attack Strategy":"Evasion",
    "Attacker's System\/Model knowledge":"WM \/ BS",
    "Attack\/Error Specificity":"AG \/ ES",
    "Failure Specificity":"Specific",
    "Model-level results":"Misprediction of the steering wheel angle",
    "System-level results (Failure Propagation)":"Driving off-road, colliding with road curbs, crashing into obstacles, and having a car crash with oncoming traffic"
  },
  {
    "Ref":"[13]",
    "Paper Title":"Invisible for both camera and LiDAR: Security of multi-sensor fusion based perception in autonomous driving",
    "App Domain":"Cars",
    "DL Model Under Attack":"(A5-L, A5-C) In-road obstacle detection (Perception)",
    "System Under attack":"Baidu Apollo in LGSVL simulator v5 (MSF)",
    "Attack Scenario":"Av on a single lane road",
    "Attacked Target":"Roads",
    "Attacker's Capability":"Placing a 3D traffic cone that resembles a broken cone on the road",
    "Attack Strategy":"Evasion",
    "Attacker's System\/Model knowledge":"WM \/ BS",
    "Attack\/Error Specificity":"AS \/ ES",
    "Failure Specificity":"Specific",
    "Model-level results":"Failing to detect an adversarial object",
    "System-level results (Failure Propagation)":"Crashing into the adversarial object"
  },
  {
    "Ref":"[14]",
    "Paper Title":"Too good to be safe: Tricking lane detection in autonomous driving with crafted perturbations",
    "App Domain":"Cars",
    "DL Model Under Attack":"Tesla's APE lane recognition (AutoPilot ECU, Electronic Control Unit) (Perception)",
    "System Under attack":"Tesla model S (SSF)",
    "Attack Scenario":"AVs on roads driving into empty spaces in road line markings",
    "Attacked Target":"Roads",
    "Attacker's Capability":"Painting or attaching perturbations on the road surface",
    "Attack Strategy":"Evasion",
    "Attacker's System\/Model knowledge":"BM \/ BS",
    "Attack\/Error Specificity":"AG \/ ES",
    "Failure Specificity":"Specific",
    "Model-level results":"Detecting the perturbation as a real line",
    "System-level results (Failure Propagation)":"Following the fake line into oncoming traffic"
  },
  {
    "Ref":"[15]",
    "Paper Title":"Robust roadside physical adversarial attack against deep learning in LiDAR perception modules",
    "App Domain":"Cars",
    "DL Model Under Attack":"PointRCNN and PointPillar and PV-RCNN (Perception)",
    "System Under attack":"Baidu Apollo in LGSVL simulator (Lincoln MKZ car) (MSF)",
    "Attack Scenario":"AVs driving on a single lane road",
    "Attacked Target":"Roadsides",
    "Attacker's Capability":"Put adversarial objects on the roadside",
    "Attack Strategy":"Evasion",
    "Attacker's System\/Model knowledge":"WM & BM \/ BS",
    "Attack\/Error Specificity":"AG \/ ES",
    "Failure Specificity":"Generic",
    "Model-level results":"Detecting adversarial objects as real cars",
    "System-level results (Failure Propagation)":"Stopping completely or suddenly changing lane"
  },
  {
    "Ref":"[16]",
    "Paper Title":"ML-driven malware that targets AV safety",
    "App Domain":"Cars",
    "DL Model Under Attack":"Kalman Filter in YOLO v3 (Perception)",
    "System Under attack":"Baidu Apollo in LGSVL simulator (MSF)",
    "Attack Scenario":"AVs on a road with pedestrians and vehicles in front of the car",
    "Attacked Target":"Input image",
    "Attacker's Capability":"Installing malware to gain access to the live camera feed and modify its ourput",
    "Attack Strategy":"Evasion",
    "Attacker's System\/Model knowledge":"WM \/ WS",
    "Attack\/Error Specificity":"AS \/ ES",
    "Failure Specificity":"Specific",
    "Model-level results":"Misdetection or failure to detect cars or pedestrians",
    "System-level results (Failure Propagation)":"Emergency braking or unsafe acceleration leading to a car crash"
  },
  {
    "Ref":"[17]",
    "Paper Title":"Attacking vision-based perception in end-to-end autonomous driving models",
    "App Domain":"Cars",
    "DL Model Under Attack":"Conditional Imitation and Reinforcement learning (E2E) in CARLA",
    "System Under attack":"End to end driving system in CARLA (SSF)",
    "Attack Scenario":"AVs in turns and intersections",
    "Attacked Target":"Roads",
    "Attacker's Capability":"Attaching stickers or painting adversarial lane markings on the road.",
    "Attack Strategy":"Evasion",
    "Attacker's System\/Model knowledge":"BM \/ BS",
    "Attack\/Error Specificity":"AS \/ ES",
    "Failure Specificity":"Specific",
    "Model-level results":"Incorrectly detecting lines (wrong control decisions)",
    "System-level results (Failure Propagation)":"Moving into another lane or veering out of bounds, resulting in collisions with road walls"
  },
  {
    "Ref":"[18]",
    "Paper Title":"Feasibility and suppression of adversarial patch attacks on end-to-end vehicle control",
    "App Domain":"Cars",
    "DL Model Under Attack":"DriveNet (an extension of Dave2) (E2E)",
    "System Under attack":"Autonomous Driving agent in CARLA (SSF)",
    "Attack Scenario":"AVs driving past a roadside billboard",
    "Attacked Target":"Billboard",
    "Attacker's Capability":"Placing adversarial patches on billboards located on the right side of the roadside",
    "Attack Strategy":"Evasion",
    "Attacker's System\/Model knowledge":"WM \/ BS",
    "Attack\/Error Specificity":"AS \/ EG",
    "Failure Specificity":"Specific",
    "Model-level results":"Misprediction of the steering wheel angle",
    "System-level results (Failure Propagation)":"Collision with the poster"
  },
  {
    "Ref":"[19]",
    "Paper Title":"Phantom of the ADAS: split-second phantom attacks",
    "App Domain":"Cars",
    "DL Model Under Attack":"Faster_rcnn_inception_v2 and Tesla's (Perception) model",
    "System Under attack":"Tesla Model X HW 2.5\/3 & Renault Captur (equipped with Mobileye 630) (MSF)",
    "Attack Scenario":"AVs driving",
    "Attacked Target":"The environment (anywhere with a smooth surface)",
    "Attacker's Capability":"Projecting a phantom using a projector or embedding the phantom on a digital advertising billboard",
    "Attack Strategy":"Evasion",
    "Attacker's System\/Model knowledge":"BM \/ BS",
    "Attack\/Error Specificity":"AG \/ EG",
    "Failure Specificity":"Generic",
    "Model-level results":"Detecting phantoms as real road signs or real-world objects",
    "System-level results (Failure Propagation)":"Acting according to the detected object (Brake or decelerate or follow a phantom lane into collision or into the upcoming lane and, etc...)"
  },
  {
    "Ref":"[20]",
    "Paper Title":"Adversarial sensor attack on LiDAR-based perception",
    "App Domain":"Cars",
    "DL Model Under Attack":"DNN of the Lidar-based (Perception) module in Baidu Apollo",
    "System Under attack":"Driving agent in Baidu Apollo (MSF)",
    "Attack Scenario":"AVs driving",
    "Attacked Target":"LIDAR Sensor",
    "Attacker's Capability":"Injecting spoofed LiDAR data points by shooting lasers at the AV",
    "Attack Strategy":"Evasion",
    "Attacker's System\/Model knowledge":"WM \/ BS",
    "Attack\/Error Specificity":"AG \/ ES",
    "Failure Specificity":"Specific",
    "Model-level results":"Detecting nonexistent obstacles",
    "System-level results (Failure Propagation)":"Emergency braking or the vehicle freezing"
  },
  {
    "Ref":"[21]",
    "Paper Title":"Trojaning attack on neural networks",
    "App Domain":"Cars",
    "DL Model Under Attack":"NN model of Udacity Simulator (E2E)",
    "System Under attack":"Udacity Simulator (SSF)",
    "Attack Scenario":"AVs driving",
    "Attacked Target":"Billboards",
    "Attacker's Capability":"Retraining the model with Trojan data and attaching it to billboards.",
    "Attack Strategy":"Poisoning",
    "Attacker's System\/Model knowledge":"WM \/ BS",
    "Attack\/Error Specificity":"AG \/ ES",
    "Failure Specificity":"Specific",
    "Model-level results":"Misprediction of the steering wheel angle",
    "System-level results (Failure Propagation)":"Moving to the right and then going off the road"
  }
]
