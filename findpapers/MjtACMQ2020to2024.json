{
  "databases": [
    "acm"
  ],
  "limit": null,
  "limit_per_database": null,
  "number_of_papers": 89,
  "number_of_papers_by_database": {
    "ACM": 89
  },
  "papers": [
    {
      "abstract": "Testing Autonomous Driving Systems (ADS) is essential for safe development of self-driving cars. For thorough and realistic testing, ADS are usually embedded in a simulator and tested in interaction with the simulated environment. However, their high complexity and the multiple safety requirements lead to costly and ineffective testing. Recent techniques exploit many-objective strategies and ML to efficiently search the huge input space. Despite the indubitable advances, the need for smartening the search keep being pressing. This article presents CART (CAusal-Reasoning-driven Testing), a new technique that formulates testing as a causal reasoning task. Learning causation, unlike correlation, allows assessing the effect of actively changing an input on the output, net of possible confounding variables. CART first infers the causal relations between test inputs and outputs, then looks for promising tests by querying the learnt model. Only tests suggested by the model are run on the simulator. An extensive empirical evaluation, using Pylot as ADS and CARLA as simulator, compares CART with state-of-the-art algorithms used recently on ADS. CART shows a significant gain in exposing more safety violations and more efficiently. More broadly, the work opens to a wider exploitation of causal learning beside (or on top of) ML for testing-related tasks.",
      "authors": [
        "Luca Giamattei",
        "Antonio Guerriero",
        "Roberto Pietrantuono",
        "Stefano Russo"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3635709",
      "keywords": [
        "Causal Reasoning",
        "AI Testing",
        "Search-based Software Testing",
        "Autonomous Vehicles",
        "Self-driving cars"
      ],
      "number_of_pages": null,
      "pages": null,
      "publication": {
        "category": "Journal",
        "cite_score": 7.1,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "1049-331X",
        "publisher": "Association for Computing Machinery (ACM)",
        "sjr": 1.198,
        "snip": 2.199,
        "subject_areas": [
          "Software"
        ],
        "title": "ACM Trans. Softw. Eng. Methodol."
      },
      "publication_date": "2023-12-05",
      "selected": null,
      "title": "Causality-driven Testing of Autonomous Driving Systems",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3635709"
      ]
    },
    {
      "abstract": "\nWe believe there is great need for developing scalable quantitative robustness verification techniques for neural networks. Formal verification techniques can provide guarantees of correctness, but most existing approaches do not provide quantitative robustness measures and are not effective in analyzing real-world network sizes. On the other hand, sampling-based quantitative robustness is not hindered much by the size of networks but cannot provide sound guarantees of quantitative results. We believe more research is needed to address the limitations of both symbolic and sampling-based verification approaches and create sound, scalable techniques for quantitative robustness verification of neural networks.",
      "authors": [
        "Mara Downing",
        "Tevfik Bultan"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3617574.3617862",
      "keywords": [
        "Safety-Critical Systems",
        "Quantitative Verification",
        "Neural Network Verification"
      ],
      "number_of_pages": 4,
      "pages": "22-25",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9798400703799",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the 1st International Workshop on Dependability and Trustworthiness of Safety-Critical Systems with Machine Learned Components"
      },
      "publication_date": "2023-12-04",
      "selected": null,
      "title": "The Case for Scalable Quantitative Neural Network Analysis",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3617574.3617862"
      ]
    },
    {
      "abstract": " ",
      "authors": [
        "Binhui Tang",
        "Hai Da",
        "Bochang Wang",
        "Junfeng Wang"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1002/ett.4840",
      "keywords": [],
      "number_of_pages": 23,
      "pages": "",
      "publication": {
        "category": "Journal",
        "cite_score": 6.4,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "2161-3915",
        "publisher": "John Wiley and Sons Ltd",
        "sjr": 0.802,
        "snip": 1.015,
        "subject_areas": [
          "Electrical and Electronic Engineering"
        ],
        "title": "Trans. Emerg. Telecommun. Technol."
      },
      "publication_date": "2023-11-12",
      "selected": null,
      "title": "MUDROID: Android malware detection and classification based on permission and behavior for autonomous vehicles",
      "urls": [
        "https://dl.acm.org/doi/10.1002/ett.4840"
      ]
    },
    {
      "abstract": " Machine learning (ML) has seen a major rise in popularity on edge devices in recent years, ranging from IoT devices to self-driving cars. Security in a critical consideration on these platforms. State-of-the-art security-centric ML algorithms (e.g., differentially private ML, adversarial robustness) require noise sampled from Laplace or Gaussian distributions. Edge accelerators lack CPUs\u00a0[15, 25, 36, 50] to add such noise. Existing hardware approaches to generate noise on-the-fly incur high overheads and leak side-channel information that can undermine security\u00a0[34, 47]. To remedy this, we propose DINAR,1 lightweight hardware that enables noise addition from arbitrary distributions. For differentially private ML, DINAR enables noise addition while incurring 23 \u00d7 lower area and 40 \u00d7 lower energy compared to producing noise directly on-chip.",
      "authors": [
        "Karthik Ganesan",
        "Viktor Karyofyllis",
        "Julianne Attai",
        "Ahmed Hamoda",
        "Natalie Enright Jerger"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3623652.3623665",
      "keywords": [
        "adversarial attacks",
        "Machine learning security",
        "differential privacy",
        "Neural network accelerators"
      ],
      "number_of_pages": 9,
      "pages": "38-46",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9798400716232",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the 12th International Workshop on Hardware and Architectural Support for Security and Privacy"
      },
      "publication_date": "2023-10-29",
      "selected": null,
      "title": "DINAR: Enabling Distribution Agnostic Noise Injection in Machine Learning Hardware",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3623652.3623665"
      ]
    },
    {
      "abstract": "Electronic proceedings of IJCAI 2023",
      "authors": [
        "Hannah Kim",
        "Celia Cintas",
        "Girmaw Abebe Tadesse",
        "Skyler Speakman"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.24963/ijcai.2023/107",
      "keywords": [],
      "number_of_pages": 9,
      "pages": "965-973",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "978-1-956792-03-4",
        "issn": "1045-0823",
        "publisher": null,
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence"
      },
      "publication_date": "2023-08-19",
      "selected": null,
      "title": "Spatially Constrained Adversarial Attack Detection and Localization in the Representation Space of Optical Flow Networks",
      "urls": [
        "https://www.ijcai.org/proceedings/2023/0107.pdf",
        "https://dl.acm.org/doi/10.24963/ijcai.2023/107"
      ]
    },
    {
      "abstract": "Even as our ability to counter cyber attacks improves, it is inevitable that threat actors may compromise a system through either exploited vulnerabilities and/or user error. Aside from material losses, cyber attacks also undermine trust. Self-Driving Cars (SDCs) are...",
      "authors": [
        "Marcinkiewicz, Victoria",
        "Morgan, Phillip L."
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1007/978-3-031-35822-7_22",
      "keywords": [
        "Trust",
        "Cyber Security",
        "Self-Driving Cars"
      ],
      "number_of_pages": 15,
      "pages": "323-337",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": 2.2,
        "is_potentially_predatory": false,
        "isbn": "978-3-031-35821-0",
        "issn": "1611-3349",
        "publisher": "Springer Verlag",
        "sjr": 0.32,
        "snip": 0.542,
        "subject_areas": [
          "Theoretical Computer Science",
          "Computer Science (all)"
        ],
        "title": "HCI for Cybersecurity, Privacy and Trust: 5th International Conference, HCI-CPT 2023, Held as Part of the 25th HCI International Conference, HCII 2023, Copenhagen, Denmark, July 23\u201328, 2023, Proceedings"
      },
      "publication_date": "2023-07-23",
      "selected": null,
      "title": "Trust and Blame in Self-driving Cars Following a Successful Cyber Attack",
      "urls": [
        "https://link.springer.com/content/pdf/10.1007/978-3-031-35822-7_22.pdf",
        "https://dl.acm.org/doi/10.1007/978-3-031-35822-7_22"
      ]
    },
    {
      "abstract": "The past decade has witnessed the rapid development of autonomous driving systems. However, it remains a daunting task to achieve full autonomy, especially when it comes to understanding the ever-changing, complex driving scenes. To alleviate the difficulty of perception, self-driving vehicles are usually equipped with a suite of sensors (e.g., cameras, LiDARs), hoping to capture the scenes with overlapping perspectives to minimize blind spots. Fusing these data streams and exploiting their complementary properties is thus rapidly becoming the current trend. Nonetheless, combining data that are captured by different sensors with drastically different ranging/ima-ging mechanisms is not a trivial task; instead, many factors need to be considered and optimized. If not careful, data from one sensor may act as noises to data from another sensor, with even poorer results by fusing them. Thus far, there has been no in-depth guidelines to designing the multi-modal fusion based 3D perception algorithms. To fill in the void and motivate further investigation, this survey conducts a thorough study of tens of recent deep learning based multi-modal 3D detection networks (with a special emphasis on LiDAR-camera fusion), focusing on their fusion stage (i.e., when to fuse), fusion inputs (i.e., what to fuse), and fusion granularity (i.e., how to fuse). These important design choices play a critical role in determining the performance of the fusion algorithm. In this survey, we first introduce the background of popular sensors used for self-driving, their data properties, and the corresponding object detection algorithms. Next, we discuss existing datasets that can be used for evaluating multi-modal 3D object detection algorithms. Then we present a review of multi-modal fusion based 3D detection networks, taking a close look at their fusion stage, fusion input and fusion granularity, and how these design choices evolve with time and technology. After the review, we discuss open challenges as well as possible solutions. We hope that this survey can help researchers to get familiar with the field and embark on investigations in the area of multi-modal 3D object detection.",
      "authors": [
        "Wang, Yingjie",
        "Mao, Qiuyu",
        "Zhu, Hanqi",
        "Deng, Jiajun",
        "Zhang, Yu",
        "Ji, Jianmin",
        "Li, Houqiang",
        "Zhang, Yanyong"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1007/s11263-023-01784-z",
      "keywords": [
        "3D object detection",
        "Autonomous driving",
        "Sensor fusion",
        "Multi-modal fusion"
      ],
      "number_of_pages": 31,
      "pages": "2122-2152",
      "publication": {
        "category": "Journal",
        "cite_score": 22.5,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "0920-5691",
        "publisher": "Springer Netherlands",
        "sjr": 3.369,
        "snip": 5.07,
        "subject_areas": [
          "Artificial Intelligence",
          "Computer Vision and Pattern Recognition",
          "Software"
        ],
        "title": "International Journal of Computer Vision"
      },
      "publication_date": "2023-05-17",
      "selected": null,
      "title": "Multi-Modal 3D Object Detection in Autonomous Driving: A Survey",
      "urls": [
        "https://dl.acm.org/doi/10.1007/s11263-023-01784-z",
        "https://link.springer.com/content/pdf/10.1007/s11263-023-01784-z.pdf"
      ]
    },
    {
      "abstract": "EvoMBT has been applied for the testing 3D games and cyber-physical systems.",
      "authors": [
        "Raihana Ferdous",
        "Chia-kang Hung",
        "Fitsum Kifetew",
        "Davide Prandi",
        "Angelo Susi"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1016/j.scico.2023.102942",
      "keywords": [
        "Cyber-physical systems",
        "Search-based testing",
        "Game play testing",
        "Model-based testing"
      ],
      "number_of_pages": 6,
      "pages": "",
      "publication": {
        "category": "Journal",
        "cite_score": 3.5,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "0167-6423",
        "publisher": "Elsevier B.V.",
        "sjr": 0.517,
        "snip": 1.123,
        "subject_areas": [
          "Modeling and Simulation",
          "Information Systems",
          "Computational Theory and Mathematics",
          "Software"
        ],
        "title": "Sci. Comput. Program."
      },
      "publication_date": "2023-04-01",
      "selected": null,
      "title": "         EvoMBT: Evolutionary model based testing&#x25aa;",
      "urls": [
        "https://dl.acm.org/doi/10.1016/j.scico.2023.102942"
      ]
    },
    {
      "abstract": "Safe deployment of self-driving cars (SDC) necessitates thorough simulated and in-field testing. Most testing techniques consider virtualized SDCs within a simulation environment, whereas less effort has been directed towards assessing whether such techniques transfer to and are effective with a physical real-world vehicle. In this paper, we shed light on the problem of generalizing testing results obtained in a driving simulator to a physical platform and provide a characterization and quantification of the sim2real gap affecting SDC testing. In our empirical study, we compare SDC testing when deployed on a physical small-scale vehicle versus its digital twin. Due to the unavailability of driving quality indicators from the physical platform, we use neural rendering to estimate them through visual odometry, hence allowing full comparability with the digital twin. Then, we investigate the transferability of behavior and failure exposure between virtual and real-world environments, targeting both unintended abnormal test data and intended adversarial examples. Our study shows that, despite the usage of a faithful digital twin, there are still critical shortcomings that contribute to the reality gap between the virtual and physical world, threatening existing testing solutions that only consider virtual SDCs. On the positive side, our results present the test configurations for which physical testing can be avoided, either because their outcome does transfer between virtual and physical environments, or because the uncertainty profiles in the simulator can help predict their outcome in the real world.",
      "authors": [
        "Andrea Stocco",
        "Brian Pulfer",
        "Paolo Tonella"
      ],
      "categories": null,
      "citations": 4,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1109/TSE.2022.3202311",
      "keywords": [],
      "number_of_pages": 13,
      "pages": "1928-1940",
      "publication": {
        "category": "Journal",
        "cite_score": 9.5,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "0098-5589",
        "publisher": "Institute of Electrical and Electronics Engineers Inc.",
        "sjr": 1.713,
        "snip": 3.516,
        "subject_areas": [
          "Software"
        ],
        "title": "IEEE Trans. Softw. Eng."
      },
      "publication_date": "2023-04-01",
      "selected": null,
      "title": "Mind the Gap! A Study on the Transferability of Virtual Versus Physical-World Testing of Autonomous Driving Systems",
      "urls": [
        "https://dl.acm.org/doi/10.1109/TSE.2022.3202311"
      ]
    },
    {
      "abstract": "Self-driving vehicles promise many safety, mobility, and environmental benefits. However, users&#x2019; lack of trust and acceptance may threaten the success and potential of this technology. Monitoring the driver&#x2019;s emotional state is one way to address this challenge. Empathetic automation can respond to the driver&#x2019;s state and improve the experience and acceptance of self-driving vehicle drivers. In this study, 24 participants rode in a self-driving vehicle simulator and experienced three automation styles (aggressive, moderate, conservative) and four intersection types (with and without a stop sign, and with and without traffic.) We identified the observed drivers&#x2019; emotions from the video data and labeled the video frames using the dimensional and discrete emotion models to examine how automation behavior affects the driver&#x2019;s emotional state. We used multilevel Bayesian linear regression and multilevel Dirichlet regression to model the continuous and discrete emotions, respectively. The automation driving style effect varied for each participant. The same conditions provoked positive responses for some participants, and negative for others. Furthermore, the results showed that intersection type, the position within the intersection, and their interaction affected the driver&#x2019;s emotional state. This indicates that personalized driver state monitoring systems might enhance drivers&#x2019; experience in self-driving vehicles.",
      "authors": [
        "Areen Alsaid",
        "John D. Lee",
        "Sofia I. Noejovich",
        "Abdallah Chehade"
      ],
      "categories": null,
      "citations": 1,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1109/TITS.2023.3239880",
      "keywords": [],
      "number_of_pages": 11,
      "pages": "3963-3973",
      "publication": {
        "category": "Journal",
        "cite_score": 11.6,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "1524-9050",
        "publisher": "Institute of Electrical and Electronics Engineers Inc.",
        "sjr": 2.674,
        "snip": 3.544,
        "subject_areas": [
          "Computer Science Applications",
          "Automotive Engineering",
          "Mechanical Engineering"
        ],
        "title": "Trans. Intell. Transport. Sys."
      },
      "publication_date": "2023-04-01",
      "selected": null,
      "title": "The Effect of Vehicle Automation Styles on Drivers&amp;#x2019; Emotional State",
      "urls": [
        "https://dl.acm.org/doi/10.1109/TITS.2023.3239880"
      ]
    },
    {
      "abstract": "With the recent advances in the automobile industry and the emergence of smart self-driving vehicles, the increasing need for proper and optimal Vehicular Ad-hoc Network (VANet) protocols has drawn the attention of many researchers. Nevertheless, the VANet community has yet to agree on a unified and suitable set of protocols for such networks. One of the major concerns in these networks is security considerations, which are significant because of the specific characteristics of VANet. In this article, we aim to address the location privacy and reliability issues in VANet routing protocols. We propose DARVAN, a fully decentralized infrastructure that provides anonymous and reliable routing in VANets. By employing a distributed database and collective consensus, DARVAN minimizes the exposure of critical data, which is conventionally stored and processed in centralized units. DARVAN is deployed by modifying the I2P protocol, which aims to improve routing reliability and resilience to many adversary activities in VANets. Specifically, with DARVAN, we present an effective and efficient network-level mitigation for Sybil attacks in Vanets. Our extensive simulations on NS3 show that DARVAN performs well in terms of packet delivery ratio, overhead, delay, and reliability compared to the previous anonymous scheme proposed for VANet routing.",
      "authors": [
        "Saleh Khalaj Monfared",
        "Saeed Shokrollahi"
      ],
      "categories": null,
      "citations": 1,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1016/j.comnet.2023.109561",
      "keywords": [
        "Reliability",
        "Anonymity",
        "VANets",
        "Routing",
        "Decentralized"
      ],
      "number_of_pages": 15,
      "pages": "",
      "publication": {
        "category": "Journal",
        "cite_score": 10.7,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "1389-1286",
        "publisher": "Elsevier B.V.",
        "sjr": 1.625,
        "snip": 1.711,
        "subject_areas": [
          "Computer Networks and Communications"
        ],
        "title": "Comput. Netw."
      },
      "publication_date": "2023-03-01",
      "selected": null,
      "title": "DARVAN: A fully decentralized anonymous and reliable routing for VANets",
      "urls": [
        "https://dl.acm.org/doi/10.1016/j.comnet.2023.109561"
      ]
    },
    {
      "abstract": "Multispectral object detection plays a vital role in safety-critical vision systems that require an around-the-clock operation and encounter dynamic real-world situations(e.g., self-driving cars and autonomous surveillance systems). Despite its crucial competence in safety-related applications, its security against physical attacks is severely understudied. We investigate the vulnerability of multispectral detectors against physical attacks by proposing a new physical method: Multispectral Invisible Coating. Utilizing transparent Low-e films, we realize a laminated visible-thermal physical attack by attaching Low-e films over a visible attack printing. Moreover, we apply our physical method to manufacture a Multispectral Invisible Suit that hides persons from the multiple view angles of Multispectral detectors. To simulate our attack under various surveillance scenes, we constructed a large-scale multispectral pedestrian dataset which we will release in public. Extensive experiments show that our proposed method effectively attacks the state-of-the-art multispectral detector both in the digital space and the physical world.",
      "authors": [
        "Taeheon Kim",
        "Youngjoon Yu",
        "Yong Man Ro"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1609/aaai.v37i1.25197",
      "keywords": [],
      "number_of_pages": 9,
      "pages": "1151-1159",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "978-1-57735-880-0",
        "issn": null,
        "publisher": "AAAI Press",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence and Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence and Thirteenth Symposium on Educational Advances in Artificial Intelligence"
      },
      "publication_date": "2023-02-07",
      "selected": null,
      "title": "Multispectral Invisible Coating: Laminated Visible-Thermal Physical Attack against Multispectral Object Detectors Using Transparent Low-E Films",
      "urls": [
        "https://dl.acm.org/doi/10.1609/aaai.v37i1.25197"
      ]
    },
    {
      "abstract": "WOGAN is an online test generation algorithm based on Wasserstein generative adversarial networks. In this note, we present how WOGAN works and summarize its performance in the SBST 2022 CPS tool competition concerning the AI of a self-driving car.",
      "authors": [
        "Jarkko Peltom\u00e4ki",
        "Frankie Spencer",
        "Ivan Porres"
      ],
      "categories": null,
      "citations": 2,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3526072.3527535",
      "keywords": [],
      "number_of_pages": 2,
      "pages": "53-54",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450393188",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the 15th Workshop on Search-Based Software Testing"
      },
      "publication_date": "2023-02-03",
      "selected": null,
      "title": "WOGAN at the SBST 2022 CPS tool competition",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3526072.3527535"
      ]
    },
    {
      "abstract": "Due to the great advantage of LiDAR sensors in perceiving complex driving environments, LiDAR-based 3D object detection has recently drawn significant attention in autonomous driving. Although many advanced LiDAR object detection models have been developed, their designs are mainly based on deep learning approaches, which are usually data-hungry and expensive to train. Thus, it is common for some LiDAR perception system developers or self-driving car companies to collect training data from different sources (e.g., self-driving car users) or outsource the training work to a third party. However, these practices provide opportunities for backdoor attacks, where the attacker aims to inject a hidden trigger pattern into the victim detection model by poisoning its training set and let the model fail to detect objects when the trigger presents in the inference phase. Although backdoor attacks have posed serious security concerns, the vulnerability of LiDAR object detection to such attacks has not yet been studied. To fill the research gap, in this paper, we present the first study on backdoor attacks against LiDAR object detection in autonomous driving. Specifically, we propose a novel backdoor attack strategy based on which the attacker can achieve the attack goal by poisoning a small number of point cloud samples. In addition, the proposed attack strategy is physically realizable, and it allows the attacker to easily perform the attack using some common objects as the triggers. To make the poisoned samples difficult to be detected, we also design a stealthy attack strategy by creating some fake vehicle point clusters to hide the injected points in the point cloud. The desirable performance of our attacks is demonstrated through both simulation and real-world case study.",
      "authors": [
        "Yan Zhang",
        "Yi Zhu",
        "Zihao Liu",
        "Chenglin Miao",
        "Foad Hajiaghajani",
        "Lu Su",
        "Chunming Qiao"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3560905.3568539",
      "keywords": [
        "backdoor attack",
        "LiDAR object detection",
        "autonomous driving"
      ],
      "number_of_pages": 15,
      "pages": "533-547",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450398862",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems"
      },
      "publication_date": "2023-01-24",
      "selected": null,
      "title": "Towards Backdoor Attacks against LiDAR Object Detection in Autonomous Driving",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3560905.3568539"
      ]
    },
    {
      "abstract": "Self-driving and connected cars are designed to make traffic safer while lowering risks and accidents. However, Security concerns about these vehicles limit their use and what they can accomplish. Cyber-attacks on these vehicles may have serious repercussions, including the loss of personal information as well as physical harm or even death. In this paper, we investigate intrusion detection on connected and autonomous vehicles using supervised machine learning techniques. The overarching goal is to develop a taxonomy for linked intrusion detection systems and supervised learning algorithms. To that end, we provide a thorough explanation of the concepts of intrusion detection systems and cyber-security attacks. Then, we demonstrate how machine learning can improve the security of future connected and autonomous vehicles by examining and evaluating how to protect sent and transferred data. Finally, a taxonomy based on these related works is offered. Based on a review of four well-known data sets in this field, we can conclude from this taxonomy that the classification performance of supervised learning algorithms is strong and encouraging.",
      "authors": [
        "Emad E. Abdallah",
        "Ahmad Aloqaily",
        "Hiba Fayez"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1016/j.procs.2023.03.040",
      "keywords": [
        "Machine Learning",
        "Cyber Security",
        "Smart City",
        "Intrusion Detection",
        "Connected Vehicle"
      ],
      "number_of_pages": 8,
      "pages": "307-314",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": 4.0,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "1877-0509",
        "publisher": "Elsevier B.V.",
        "sjr": 0.507,
        "snip": 0.885,
        "subject_areas": [
          "Computer Science (all)"
        ],
        "title": "Procedia Comput. Sci."
      },
      "publication_date": "2023-01-01",
      "selected": null,
      "title": "Identifying Intrusion Attempts on Connected and Autonomous Vehicles: A Survey",
      "urls": [
        "https://dl.acm.org/doi/10.1016/j.procs.2023.03.040"
      ]
    },
    {
      "abstract": "Nowadays, deep learning models enable numerous safety-critical applications, such as biometric authentication, medical diagnosis support, and self-driving cars. However, previous studies have frequently demonstrated that these models are attackable through slight modifications of their inputs, so-called adversarial attacks. Hence, researchers proposed investigating examples of these attacks with explainable artificial intelligence to understand them better. In this line, we developed an expert tool to explore adversarial attacks and defenses against them. To demonstrate the capabilities of our visualization tool, we worked with the publicly available CIFAR-10 dataset and generated one-pixel attacks. After that, we conducted an online evaluation with 16 experts. We found that our tool is usable and practical, providing evidence that it can support understanding, explaining, and preventing adversarial examples. ",
      "authors": [
        "Jonas Keppel",
        "Jonathan Liebers",
        "Jonas Auda",
        "Uwe Gruenefeld",
        "Stefan Schneegass"
      ],
      "categories": null,
      "citations": 1,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3568444.3568469",
      "keywords": [
        "explainability",
        "one-pixel attacks",
        "adversarial examples",
        "human-in-the-loop"
      ],
      "number_of_pages": 12,
      "pages": "231-242",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450398206",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the 21st International Conference on Mobile and Ubiquitous Multimedia"
      },
      "publication_date": "2022-12-29",
      "selected": null,
      "title": "ExplAInable Pixels: Investigating One-Pixel Attacks on Deep Learning Models with Explainable Visualizations",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3568444.3568469"
      ]
    },
    {
      "abstract": "Learning-based self-driving techniques and vehicle navigation approaches are the most hot topics in recent years. However, existing approaches typically assume the attack-free sensor data, the safety issue under large disturbance or external attack have not been well-solved. In this article, we build a simple FGSM-based attack method designed by minimizing the maximum value of the extracted visual features in order to greatly decrease the performance of the popular learning model for vehicle navigation and even make it totally fail. The proposed min-max operation based feature space attack method solves the problems of branch activation uncertainties and the lack of labels. Furthermore, we also provide a general adversarial training framework which can be used to overcome the proposed feature space attack. Simulational experiments in CARLA platform demonstrate the effectiveness and practical applicability of our attacking approach and defence strategy.",
      "authors": [
        "Hongye Wang",
        "Kefan Jin",
        "Hesheng Wang"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1109/ROBIO54168.2021.9739418",
      "keywords": [],
      "number_of_pages": 6,
      "pages": "328-333",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": null,
        "publisher": "IEEE Press",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "2021 IEEE International Conference on Robotics and Biomimetics (ROBIO)"
      },
      "publication_date": "2022-12-27",
      "selected": null,
      "title": "Attacking End-to-End Visual Navigation Model: How Weak Existing Learning-Based Approaches Can Be?",
      "urls": [
        "https://dl.acm.org/doi/10.1109/ROBIO54168.2021.9739418"
      ]
    },
    {
      "abstract": "Autonomous systems have reached a tipping point, with a myriad of self-driving cars, unmanned aerial vehicles (UAVs), and robots being widely applied and revolutionizing new applications. The continuous deployment of autonomous systems reveals the need for designs that facilitate increased resiliency and safety. The ability of an autonomous system to tolerate, or mitigate against errors, such as environmental conditions, sensor, hardware and software faults, and adversarial attacks, is essential to ensure its functional safety. Application-aware resilience metrics, holistic fault analysis frameworks, and lightweight fault mitigation techniques are being proposed for accurate and effective resilience and robustness assessment and improvement. This paper explores the origination of fault sources across the computing stack of autonomous systems, discusses the various fault impacts and fault mitigation techniques of different scales of autonomous systems, and concludes with challenges and opportunities for assessing and building next-generation resilient and robust autonomous systems.",
      "authors": [
        "Zishen Wan",
        "Karthik Swaminathan",
        "Pin-Yu Chen",
        "Nandhini Chandramoorthy",
        "Arijit Raychowdhury"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3508352.3561111",
      "keywords": [],
      "number_of_pages": 9,
      "pages": "1-9",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450392174",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the 41st IEEE/ACM International Conference on Computer-Aided Design"
      },
      "publication_date": "2022-12-22",
      "selected": null,
      "title": "Analyzing and Improving Resilience and Robustness of Autonomous Systems",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3508352.3561111"
      ]
    },
    {
      "abstract": "In a future of self-driving and connected vehicles, cooperative driving will be the key to guarantee that not only isolated vehicles can hit the road safely on their own, but that the collective of vehicles displays efficient and safe behaviours. Intersection...",
      "authors": [
        "Mariani, Stefano",
        "Ferrari, Dario",
        "Zambonelli, Franco"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1007/978-3-031-21203-1_3",
      "keywords": [
        "Intersection crossing",
        "Coordination",
        "Cooperative driving",
        "Multi-agent system",
        "Argumentation"
      ],
      "number_of_pages": 17,
      "pages": "37-53",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": 2.2,
        "is_potentially_predatory": false,
        "isbn": "978-3-031-21202-4",
        "issn": "1611-3349",
        "publisher": "Springer Verlag",
        "sjr": 0.32,
        "snip": 0.542,
        "subject_areas": [
          "Theoretical Computer Science",
          "Computer Science (all)"
        ],
        "title": "PRIMA 2022: Principles and Practice of Multi-Agent Systems: 24th International Conference, Valencia, Spain, November 16\u201318, 2022, Proceedings"
      },
      "publication_date": "2022-11-16",
      "selected": null,
      "title": "Cooperative Driving at\u00a0Intersections Through Agent-Based Argumentation",
      "urls": [
        "https://link.springer.com/content/pdf/10.1007/978-3-031-21203-1_3.pdf",
        "https://dl.acm.org/doi/10.1007/978-3-031-21203-1_3"
      ]
    },
    {
      "abstract": "The increase in number and types of various stakeholders interacting with self-driving vehicles expands the relevant automotive cybersecurity attack vectors that can be compromised. Furthermore, given the prominent role that human behavior plays in the lifetime of a vehicle, social and human-based factors must be considered in tandem with the technical factors when addressing cybersecurity. A focus on informing and enabling stakeholders and their corresponding actions promotes security of the vehicle through a human-focused and technology-enabled approach. Example stakeholders include the consumer operating the vehicle, the technicians working on the car, and the engineers designing the software. Strategies can be applied in both a social and technical manner to increase preventative security measures for autonomous vehicles by leveraging theoretical foundations from the criminology domain. In this work we harness a criminology theory approach to crime prevention, where we synergistically combine cybercrime theory, human factors, and technical solutions to develop a cybercrime prevention framework that accounts for a range of stakeholders relevant to an autonomous vehicle domain.",
      "authors": [
        "Nick Polanco",
        "Betty Cheng"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3550356.3561600",
      "keywords": [
        "situational crime prevention",
        "self-driving cars",
        "cybersecurity",
        "sociotechnical",
        "autonomous vehicles",
        "human-based"
      ],
      "number_of_pages": 7,
      "pages": "562-568",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450394673",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings"
      },
      "publication_date": "2022-11-09",
      "selected": null,
      "title": "Situational crime prevention for automotive cybersecurity",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3550356.3561600"
      ]
    },
    {
      "abstract": "DriveFuzz has discovered 30 new bugs in various layers of two autonomous driving systems (Autoware and CARLA Behavior Agent) and three additional bugs in the CARLA simulator. We further analyze the impact of these bugs and how an adversary may exploit them as security vulnerabilities to cause critical accidents in the real world.",
      "authors": [
        "Seulbae Kim",
        "Major Liu",
        "Junghwan \"John\" Rhee",
        "Yuseok Jeon",
        "Yonghwi Kwon",
        "Chung Hwan Kim"
      ],
      "categories": null,
      "citations": 1,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3548606.3560558",
      "keywords": [
        "fuzzing",
        "autonomous driving system"
      ],
      "number_of_pages": 15,
      "pages": "1753-1767",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450394505",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security"
      },
      "publication_date": "2022-11-07",
      "selected": null,
      "title": "DriveFuzz: Discovering Autonomous Driving Bugs through Driving Quality-Guided Fuzzing",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3548606.3560558"
      ]
    },
    {
      "abstract": "In this paper, we will first summarize various security attack scenarios against different LiDAR types. We focus on beam-steering and frequency modulated continuous wave (FMCW) LiDAR systems as they have been considered the most secure LiDAR systems proposed so far. We will show that an attacker can reverse engineer the victim's LiDAR system and build a spoofing system using commercially available electro-optical components. To do so, we will develop an electro-optical co-simulation framework in MATLAB Simulink and use that to study the feasibility of the spoofing attack in today's FMCW LiDAR systems. Finally, we propose the frequency encryption technique as a countermeasure to mitigate the possibility of spoofing FMCW beam-steering LiDAR systems. The proposed approach can ensure the security of future FMCW LiDAR systems without compromising functionality or accuracy.",
      "authors": [
        "Marziyeh Rezaei",
        "Liban Hussein",
        "Sajjad Moazeni"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3560834.3563829",
      "keywords": [
        "spoofing attack",
        "beam-steering",
        "frequency encryption",
        "lidar",
        "fmcw"
      ],
      "number_of_pages": 9,
      "pages": "35-43",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450398848",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the 2022 Workshop on Attacks and Solutions in Hardware Security"
      },
      "publication_date": "2022-11-07",
      "selected": null,
      "title": "Secure FMCW LiDAR Systems with Frequency Encryption",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3560834.3563829"
      ]
    },
    {
      "abstract": "In the present emergence of artificial intelligence, deep learning is at the core of the process. For applications ranging from self-driving vehicles to surveillance and security, computer vision has emerged as the workhorse in the area of artificial intelligence. While deep neural networks have demonstrated phenomenal success (often exceeding the capabilities of humans) in solving complex problems, recent studies have revealed that they are vulnerable to adversarial attacks in the form of subtle perturbations to inputs that cause a model to predict incorrect outputs, according to the researchers. Such disturbances are typically too subtle to be seen in photographs, but they fully trick the deep learning models, which are trained to detect them. Adversarial assaults are a severe danger to the success of deep learning in practice, and should be taken seriously. This fact has lately resulted in a significant increase in the amount of money being donated in this manner. The primary goal of this work is to improvise a design feature of attack and its defence mechanism with centralities on the each neighbours and its performance measure. The overall reduction of accuracy for the before attack and after attack with a marginal error of 5% percent is observed for each type of the Neighbours set with matrix size or even list of elements repeatedly.",
      "authors": [
        "Gutta Akshitha sai",
        "Komma Naga Sai Likhitha",
        "Maddi Pavan Kalyan",
        "Perisetla Anjani Devi",
        "Prathibhamol C."
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3549206.3549305",
      "keywords": [
        "Linear Regression (LR) Artificial Intelligence (AI)",
        "Graph convolutional Networks (GCN)"
      ],
      "number_of_pages": 9,
      "pages": "573-581",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450396752",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the 2022 Fourteenth International Conference on Contemporary Computing"
      },
      "publication_date": "2022-10-24",
      "selected": null,
      "title": "Combinational Features with centrality measurements on GCN+LR classification of Adversarial Attacks in homogenous Graphs.",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3549206.3549305"
      ]
    },
    {
      "abstract": "The use of multi-camera systems is becoming more common in self-driving cars, micro aerial vehicles or augmented reality headsets. In order to perform 3D geometric tasks, the accuracy and efficiency of relative pose estimation algorithms are very important for the multi-camera systems, and is catching significant research attention these days. The point coordinates of point correspondences (PCs) obtained from feature matching strategies have been widely used for relative pose estimation. This paper exploits known scale ratios besides the point coordinates, which are also intrinsically provided by scale invariant feature detectors (e.g., SIFT). Two-view geometry of scale ratio associated with the extracted features is derived for multi-camera systems. Thanks to the constraints provided by the scale ratio across two views, the number of PCs needed for relative pose estimation is reduced from 6 to 3. Requiring fewer PCs makes RANSAC-like randomized robust estimation significantly faster. For different point correspondence layouts, four minimal solvers are proposed for typical two-camera rigs. Extensive experiments demonstrate that our solvers have better accuracy than the state-of-the-art ones and outperform them in terms of processing time.",
      "authors": [
        "Banglei Guan",
        "Ji Zhao"
      ],
      "categories": null,
      "citations": 1,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3503161.3547788",
      "keywords": [
        "generalized camera model",
        "scale invariant feature",
        "minimal solver",
        "multi-camera system",
        "relative pose estimation"
      ],
      "number_of_pages": 9,
      "pages": "5036-5044",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450392037",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the 30th ACM International Conference on Multimedia"
      },
      "publication_date": "2022-10-10",
      "selected": null,
      "title": "Relative Pose Estimation for Multi-Camera Systems from Point Correspondences with Scale Ratio",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3503161.3547788"
      ]
    },
    {
      "abstract": "Real-time detection and motion forecasting are critical for self-driving vehicle (SDV). However, there are lots of redundant computations in the existing joint detection and prediction methods. To solve this problem, we propose feature sharing GRU (FS-GRU) which employs the convolutional gate recurrent unit (ConvGRU) to aggregate temporal context and share inter frame feature. The key component is an inter frame feature coordinate transform module with an auxiliary task returning the transformed target pose. Importantly, the feature sharing mechanism reduce so much computation cost that we can exploit long-term history information to better infer the intention of participants. The method was evaluated on large-scale public dataset, and show significant improvements over the state-of-the-art with higher accuracy and less runtime.",
      "authors": [
        "Zhikai Chen",
        "Yafei Wang",
        "Xulei Liu",
        "Xinchang Wang"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1109/ITSC55140.2022.9922356",
      "keywords": [],
      "number_of_pages": 6,
      "pages": "517-522",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": null,
        "publisher": "IEEE Press",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "2022 IEEE 25th International Conference on Intelligent Transportation Systems (ITSC)"
      },
      "publication_date": "2022-10-08",
      "selected": null,
      "title": "FS-GRU: Continuous Perception and Prediction with inter Frame Feature Sharing",
      "urls": [
        "https://dl.acm.org/doi/10.1109/ITSC55140.2022.9922356"
      ]
    },
    {
      "abstract": "Estimating depth from a monocular camera is a must for many applications, including scene understanding and reconstruction, robot vision, and self-driving cars. However, generating depth maps from single RGB images is still a challenge as object shapes are to be inferred from intensity images strongly affected by viewpoint changes, texture content and light conditions. Therefore, most current solutions produce blurry approximations of low-resolution depth maps. We propose a novel depth map estimation technique based on an autoencoder network. This network is endowed with a multi-scale architecture and a multi-level depth estimator that preserve high-level information extracted from coarse feature maps as well as detailed local information present in fine feature maps. Curvilinear saliency, which is related to curvature estimation, is exploited as a loss function to boost the depth accuracy at object boundaries and raise the performance of the estimated high-resolution depth maps. We evaluate our model on the public NYU Depth v2 and Make3D datasets. The proposed model yields superior performance on both datasets compared to the state-of-the-art, achieving an accuracy of $$~86\\%$$ and showing exceptional performance at the preservation of object boundaries and small 3D structures. The code of the proposed model is publicly available at https://github.com/SaddamAbdulrhman/MDACSFB .",
      "authors": [
        "Abdulwahab, Saddam",
        "Rashwan, Hatem A.",
        "Garcia, Miguel Angel",
        "Masoumian, Armin",
        "Puig, Domenec"
      ],
      "categories": null,
      "citations": 1,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1007/s00521-022-07663-x",
      "keywords": [
        "Deep autoencoders",
        "Multi-scale networks",
        "Curvilinear saliency",
        "Monocular depth map estimation"
      ],
      "number_of_pages": 18,
      "pages": "16423-16440",
      "publication": {
        "category": "Journal",
        "cite_score": 10.0,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "0941-0643",
        "publisher": "Springer London",
        "sjr": 1.169,
        "snip": 1.825,
        "subject_areas": [
          "Artificial Intelligence",
          "Software"
        ],
        "title": "Neural Computing and Applications"
      },
      "publication_date": "2022-10-01",
      "selected": null,
      "title": "Monocular depth map estimation based on a multi-scale deep architecture and curvilinear saliency feature boosting",
      "urls": [
        "https://link.springer.com/content/pdf/10.1007/s00521-022-07663-x.pdf",
        "https://dl.acm.org/doi/10.1007/s00521-022-07663-x"
      ]
    },
    {
      "abstract": "The future in which autonomous vehicles will become commonplace is very near. The biggest companies around the world are testing autonomous vehicles. But despite the rapid progress in this area, there are still unresolved technical problems that prevent the spreading...",
      "authors": [
        "Okimbek, Sagdat",
        "Razak, Nurlan",
        "Akhmetov, Iskander",
        "Pak, Alexandr"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1007/978-3-031-16014-1_64",
      "keywords": [],
      "number_of_pages": 14,
      "pages": "809-822",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": 2.2,
        "is_potentially_predatory": false,
        "isbn": "978-3-031-16013-4",
        "issn": "1611-3349",
        "publisher": "Springer Verlag",
        "sjr": 0.32,
        "snip": 0.542,
        "subject_areas": [
          "Theoretical Computer Science",
          "Computer Science (all)"
        ],
        "title": "Computational Collective Intelligence: 14th International Conference, ICCCI 2022, Hammamet, Tunisia, September 28\u201330, 2022, Proceedings"
      },
      "publication_date": "2022-09-28",
      "selected": null,
      "title": "Avoiding Hazardous Color Combinations in\u00a0Traffic Signs on\u00a0STN Based Model for\u00a0Autonomous Vehicles",
      "urls": [
        "https://link.springer.com/content/pdf/10.1007/978-3-031-16014-1_64.pdf",
        "https://dl.acm.org/doi/10.1007/978-3-031-16014-1_64"
      ]
    },
    {
      "abstract": "As autonomous driving technology continues to develop, communication for vehicles is becoming more important to provide an efficient and secure driving environment. Currently, vehicle-to-everything (V2X) based on fifth-generation (5G) is the only solution to meet the demanding requirements of self-driving cars in terms of ultra-low latency and ultra-high reliable connectivity under high mobility conditions, earning this technology more attention. Secure communication for vehicle-to-vehicle based on 5G (5G-V2V) is essential because vehicles decide how to maneuver and perceive situations based on the data exchanged. In this paper, we not only propose a new architecture for V2X based on 5G (5G-V2X) by utilizing network slicing (NS) to guarantee different features of V2X services but also analyze security requirements according to V2X service type. We also propose a secure V2V communication scheme based on 5G that satisfies these requirements. The security evaluation demonstrates that our scheme is secure against attacks on a V2V environment via both security proof and verification tool ProVerif. Through the performance evaluation, we prove that our scheme is more effective than the existing schemes while meeting end-to-end delay requirements for autonomous driving.",
      "authors": [
        "Hyeran Mun",
        "Minhye Seo",
        "Dong Hoon Lee"
      ],
      "categories": null,
      "citations": 2,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1109/TITS.2021.3129484",
      "keywords": [],
      "number_of_pages": 17,
      "pages": "14439-14455",
      "publication": {
        "category": "Journal",
        "cite_score": 11.6,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "1524-9050",
        "publisher": "Institute of Electrical and Electronics Engineers Inc.",
        "sjr": 2.674,
        "snip": 3.544,
        "subject_areas": [
          "Computer Science Applications",
          "Automotive Engineering",
          "Mechanical Engineering"
        ],
        "title": "Trans. Intell. Transport. Sys."
      },
      "publication_date": "2022-09-01",
      "selected": null,
      "title": "Secure Privacy-Preserving V2V Communication in 5G-V2X Supporting Network Slicing",
      "urls": [
        "https://dl.acm.org/doi/10.1109/TITS.2021.3129484"
      ]
    },
    {
      "abstract": "The idea of cooperation has been introduced to self-driving cars about a decade ago with the aim to reduce the occlusion caused by other users or the scene. More recently, the research efforts turned toward cooperative infrastructure bringing a new kind of the point of view as well as more processing power. This paper lies in this new field providing a survey that addresses the cooperative environment. We provide an overview of the architectures available to create such a system as well as the challenges introduced by the cooperation. Later, we review the main blocks involved in the perception: localization, object detection &#x0026; tracking, map generation. Each block is reviewed under the prism of cooperation. We also provide a Strengths, Weaknesses, Opportunities, and Threats (SWOT) analysis of the cooperative perception as well as a list of related scenarios alongside experimentations. Finally, we list some related datasets before concluding our paper, underlining the perspectives for further works.",
      "authors": [
        "Antoine Caillot",
        "Safa Ouerghi",
        "Pascal Vasseur",
        "R\u00e9mi Boutteau",
        "Yohan Dupuis"
      ],
      "categories": null,
      "citations": 1,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1109/TITS.2022.3153815",
      "keywords": [],
      "number_of_pages": 20,
      "pages": "14204-14223",
      "publication": {
        "category": "Journal",
        "cite_score": 11.6,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "1524-9050",
        "publisher": "Institute of Electrical and Electronics Engineers Inc.",
        "sjr": 2.674,
        "snip": 3.544,
        "subject_areas": [
          "Computer Science Applications",
          "Automotive Engineering",
          "Mechanical Engineering"
        ],
        "title": "Trans. Intell. Transport. Sys."
      },
      "publication_date": "2022-09-01",
      "selected": null,
      "title": "Survey on Cooperative Perception in an Automotive Context",
      "urls": [
        "https://dl.acm.org/doi/10.1109/TITS.2022.3153815"
      ]
    },
    {
      "abstract": "Adversarial machine learning is a prominent research area aimed towards exposing and mitigating security vulnerabilities in AI/ML algorithms and their implementations. Data poisoning and neural Trojans enable an attacker to drastically change the behavior and performance of a Convolutional Neural Network (CNN) merely by altering some of the input data during training. Such attacks can be catastrophic in the field, e.g. for self-driving vehicles. In this paper, we propose deploying a CNN as an ecosystem of variants, rather than a singular model. The ecosystem is derived from the original trained model, and though every derived model is structurally different, they are all functionally equivalent to the original and each other. We propose two complementary techniques: stochastic parameter mutation, where the weights \u03b8 of the original are shifted by a small, random amount, and a delta-update procedure which functions by XOR\u2019ing all of the parameters with an update file containing the \u0394 \u03b8 values. This technique is effective against transferability of a neural Trojan to the greater ecosystem by amplifying the Trojan\u2019s malicious impact to easily detectable levels; thus, deploying a model as an ecosystem can render the ecosystem more resilient against a neural Trojan attack.",
      "authors": [
        "Brooks Olney",
        "Robert Karam"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3471189",
      "keywords": [
        "Adversarial machine learning",
        "data poisoning",
        "countermeasures"
      ],
      "number_of_pages": 23,
      "pages": "1-23",
      "publication": {
        "category": "Journal",
        "cite_score": 4.1,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "1550-4832",
        "publisher": "Association for Computing Machinery (ACM)",
        "sjr": 0.6,
        "snip": 1.009,
        "subject_areas": [
          "Hardware and Architecture",
          "Electrical and Electronic Engineering",
          "Software"
        ],
        "title": "J. Emerg. Technol. Comput. Syst."
      },
      "publication_date": "2022-08-04",
      "selected": null,
      "title": "Diverse, Neural Trojan Resilient Ecosystem of Neural Network IP",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3471189"
      ]
    },
    {
      "abstract": "Road detection is a critically important task for self-driving cars. By employing LiDAR data, recent works have significantly improved the accuracy of road detection. However, relying on LiDAR sensors limits the application of those methods when only cameras are available. In this paper, we propose a novel road detection approach with RGB images being the only input. Specifically, we exploit pseudo-LiDAR using depth estimation and propose a feature fusion network in which RGB images and learned depth information are fused for improved road detection. To optimize the network architecture and improve the efficiency of our network, we propose a method to search for the information propagation paths. Finally, to reduce the computational cost, we design a modality distillation strategy to avoid using depth estimation networks during inference. The resulting model eliminates the reliance on LiDAR sensors and achieves state-of-the-art performance on two challenging benchmarks, KITTI and R2D.",
      "authors": [
        "Libo Sun",
        "Haokui Zhang",
        "Wei Yin"
      ],
      "categories": null,
      "citations": 1,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1109/TCSVT.2022.3146305",
      "keywords": [],
      "number_of_pages": 13,
      "pages": "5386-5398",
      "publication": {
        "category": "Journal",
        "cite_score": 11.2,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "1051-8215",
        "publisher": "Institute of Electrical and Electronics Engineers Inc.",
        "sjr": 1.491,
        "snip": 2.443,
        "subject_areas": [
          "Electrical and Electronic Engineering",
          "Media Technology"
        ],
        "title": "IEEE Trans. Cir. and Sys. for Video Technol."
      },
      "publication_date": "2022-08-01",
      "selected": null,
      "title": "Pseudo-LiDAR-Based Road Detection",
      "urls": [
        "https://dl.acm.org/doi/10.1109/TCSVT.2022.3146305"
      ]
    },
    {
      "abstract": "With advancements in technology, an important issue is ensuring the security of self-driving cars. Unfortunately, hackers have been developing increasingly complex and harmful cyberattacks, making them difficult to detect. Furthermore, due to the diversity of the...",
      "authors": [
        "Bhavsar, Mansi",
        "Roy, Kaushik",
        "Liu, Zhipeng",
        "Kelly, John",
        "Gokaraju, Balakrishna"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1007/978-3-031-08530-7_43",
      "keywords": [
        "ML model",
        "Cyberattacks",
        "Autonomous vehicle",
        "Feature engineering",
        "Intrusion",
        "Accuracy",
        "Data preprocessing",
        "Machine learning"
      ],
      "number_of_pages": 11,
      "pages": "505-515",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": 2.2,
        "is_potentially_predatory": false,
        "isbn": "978-3-031-08529-1",
        "issn": "1611-3349",
        "publisher": "Springer Verlag",
        "sjr": 0.32,
        "snip": 0.542,
        "subject_areas": [
          "Theoretical Computer Science",
          "Computer Science (all)"
        ],
        "title": "Advances and Trends in Artificial Intelligence. Theory and Practices in Artificial Intelligence: 35th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2022, Kitakyushu, Japan, July 19\u201322, 2022, Proceedings"
      },
      "publication_date": "2022-07-19",
      "selected": null,
      "title": "Intrusion-Based Attack Detection Using Machine Learning Techniques for Connected Autonomous Vehicle",
      "urls": [
        "https://link.springer.com/content/pdf/10.1007/978-3-031-08530-7_43.pdf",
        "https://dl.acm.org/doi/10.1007/978-3-031-08530-7_43"
      ]
    },
    {
      "abstract": "This paper investigates the cyber-security problem for autonomous vehicles under sensor attacks. In particular, a model-based framework is proposed which can detect sensor attacks and identify their sources in order to achieve the secure localization of self-driving vehicles. To ensure robustness of the vehicle against cyber-attacks, sensor redundancy is introduced, that is to deploy multiple sensors, each of which provides real-time pose observations of the vehicle. A bank of attack detectors is developed to capture anomalies in each sensor measurement, which is a combination of an extended Kalman filter (EKF) and a cumulative sum (CUSUM) discriminator. EKFs are employed to estimate the vehicle position and orientation recursively, while each CUSUM discriminator is designed to analyze the residual generated by its combined EKF to detect the possible deviation of the sensor measurement from the expected pose derived according to the mathematical model of the vehicle. To monitor the inconsistency amongst multiple sensor measurements, an auxiliary detector is introduced which fuses observations from multiple sensors. Based on the results of all the detectors, a rule-based isolation scheme is developed to identify the source anomalous sensor. The effectiveness of our proposed framework has been demonstrated on real vehicle data.",
      "authors": [
        "Yuanzhe Wang",
        "Qipeng Liu",
        "Ehsan Mihankhah",
        "Chen Lv",
        "Danwei Wang"
      ],
      "categories": null,
      "citations": 1,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1109/TITS.2021.3077015",
      "keywords": [],
      "number_of_pages": 13,
      "pages": "8247-8259",
      "publication": {
        "category": "Journal",
        "cite_score": 11.6,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "1524-9050",
        "publisher": "Institute of Electrical and Electronics Engineers Inc.",
        "sjr": 2.674,
        "snip": 3.544,
        "subject_areas": [
          "Computer Science Applications",
          "Automotive Engineering",
          "Mechanical Engineering"
        ],
        "title": "Trans. Intell. Transport. Sys."
      },
      "publication_date": "2022-07-01",
      "selected": null,
      "title": "Detection and Isolation of Sensor Attacks for Autonomous Vehicles: Framework, Algorithms, and Validation",
      "urls": [
        "https://dl.acm.org/doi/10.1109/TITS.2021.3077015"
      ]
    },
    {
      "abstract": "Predicting the future trajectories of multiple pedestrians in certain scenes is critical for autonomous moving platforms (like, self\u00e2\u0080\u0090driving cars and social robots). In this paper, we propose a novel Generative Adversarial Network model with Transformers, which simulates the pedestrian distribution to capture the uncertainty of the predicted paths and generate more reasonable future trajectories. The design of our method includes a generator and a discriminator. The generator mainly contains an encoder, a decoder, and a prediction module. Specifically, the encoder and the decoder comprise multihead convolutional self\u00e2\u0080\u0090attention to learn the sequence of historical movement, and the prediction module incorporates the Mish Feed\u00e2\u0080\u0090Forward Network\u00a0to yield the predicted target. The discriminator takes both the predicted paths and ground truth as input, classifies them as socially acceptable or not. Experimental results show that the proposed method consistently boosts the performance of trajectory forecasting, and our framework surpasses several existing baselines by evaluating the results on various data sets. Code is available at https://github.com/lzz970818/Trajectory-Prediction.",
      "authors": [
        "Zezheng Lv",
        "Xiaoci Huang",
        "Wenguan Cao"
      ],
      "categories": null,
      "citations": 1,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1002/int.22724",
      "keywords": [
        "trajectory prediction",
        "multihead convolutional self\u2010attention",
        "generative adversarial network",
        "mish feed\u2010forward network",
        "transformer"
      ],
      "number_of_pages": 20,
      "pages": "4417-4436",
      "publication": {
        "category": "Journal",
        "cite_score": 9.8,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "0884-8173",
        "publisher": "Wiley-Hindawi",
        "sjr": 1.438,
        "snip": 1.842,
        "subject_areas": [
          "Human-Computer Interaction",
          "Theoretical Computer Science",
          "Artificial Intelligence",
          "Software"
        ],
        "title": "Int. J. Intell. Syst."
      },
      "publication_date": "2022-06-28",
      "selected": null,
      "title": "An improved GAN with transformers for pedestrian trajectory prediction models",
      "urls": [
        "https://dl.acm.org/doi/10.1002/int.22724"
      ]
    },
    {
      "abstract": "Visual detection is a key task in autonomous driving, and it serves as a crucial foundation for self-driving planning and control. Deep neural networks have achieved promising results in various visual tasks, but they are known to be vulnerable to adversarial attacks. A comprehensive understanding of deep visual detectors&#x2019; vulnerability is required before people can improve their robustness. However, only a few adversarial attack/defense works have focused on object detection, and most of them employed only classification and/or localization losses, ignoring the objectness aspect. In this paper, we identify a serious objectness-related adversarial vulnerability in YOLO detectors and present an effective attack strategy targeting the objectness aspect of visual detection in autonomous vehicles. Furthermore, to address such vulnerability, we propose a new objectness-aware adversarial training approach for visual detection. Experiments show that the proposed attack targeting the objectness aspect is 45.17&#x0025; and 43.50&#x0025; more effective than those generated from classification and/or localization losses on the KITTI and COCO&#x005F;traffic datasets, respectively. Also, the proposed adversarial defense approach can improve the detectors&#x2019; robustness against objectness-oriented attacks by up to 21&#x0025; and 12&#x0025; mAP on KITTI and COCO&#x005F;traffic, respectively.",
      "authors": [
        "Jung Im Choi",
        "Qing Tian"
      ],
      "categories": null,
      "citations": 1,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1109/IV51971.2022.9827222",
      "keywords": [],
      "number_of_pages": 7,
      "pages": "1011-1017",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": null,
        "publisher": "IEEE Press",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "2022 IEEE Intelligent Vehicles Symposium (IV)"
      },
      "publication_date": "2022-06-04",
      "selected": null,
      "title": "Adversarial Attack and Defense of YOLO Detectors in Autonomous Driving Scenarios",
      "urls": [
        "https://dl.acm.org/doi/10.1109/IV51971.2022.9827222"
      ]
    },
    {
      "abstract": "Optical flow estimation is an essential task in self-driving systems, which helps autonomous vehicles perceive temporal continuity information of surrounding scenes. The calculation of all-pair correlation plays an important role in many existing state-of-the-art optical flow estimation methods. However, the reliance on local knowledge often limits the model&#x2019;s accuracy under complex street scenes. In this paper, we propose a new deep network architecture for optical flow estimation in autonomous driving&#x2014;&#x2014;CSFlow, which consists of two novel modules: Cross Strip Correlation module (CSC) and Correlation Regression Initialization module (CRI). CSC utilizes a striping operation across the target image and the attended image to encode global context into correlation volumes, while maintaining high efficiency. CRI is used to maximally exploit the global context for optical flow initialization. Our method has achieved state-of-the-art accuracy on the public autonomous driving dataset KITTI-2015. Code is publicly available at https://github.com/MasterHow/CSFlow.",
      "authors": [
        "Hao Shi",
        "Yifan Zhou",
        "Kailun Yang",
        "Xiaoting Yin",
        "Kaiwei Wang"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1109/IV51971.2022.9827341",
      "keywords": [],
      "number_of_pages": 8,
      "pages": "1851-1858",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": null,
        "publisher": "IEEE Press",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "2022 IEEE Intelligent Vehicles Symposium (IV)"
      },
      "publication_date": "2022-06-04",
      "selected": null,
      "title": "CSFlow: Learning Optical Flow via Cross Strip Correlation for Autonomous Driving",
      "urls": [
        "https://dl.acm.org/doi/10.1109/IV51971.2022.9827341"
      ]
    },
    {
      "abstract": "Deep Learning is rapidly evolving to the point that it can be used in crucial safety and security applications, including self-driving vehicles, surveillance, drones, and robots. However, these deep learning models are vulnerable to attacks based on adversarial samples that are undetectable to the human eye but cause the model to misbehave. There is an increasing demand for comprehensive and in-depth analysis of behaviors of various attacks and the possible defenses against common deep learning models under several adversarial scenarios. In this study, we conducted four separate investigations. First, we examine the relationship between the model's complexity and its robustness against the studied attacks. Second, the connection between the performance and diversity of models is examined. Third, the first and second experiments were tested across different datasets to explore the impact of the dataset on the performance of the model. Four, throughout the defense strategies, the model behavior is extensively investigated. The code, trained models, and detailed settings and results are available at: https://github.com/InfoLab-SKKU/ML-Adversarial-Attacks-Analysis",
      "authors": [
        "Firuz Juraev",
        "Eldor Abdukhamidov",
        "Mohammed Abuhamad",
        "Tamer Abuhmed"
      ],
      "categories": null,
      "citations": 1,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3488932.3527278",
      "keywords": [
        "adversarial attacks",
        "defenses",
        "deep learning",
        "computer vision"
      ],
      "number_of_pages": 3,
      "pages": "1207-1209",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450391405",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the 2022 ACM on Asia Conference on Computer and Communications Security"
      },
      "publication_date": "2022-05-30",
      "selected": null,
      "title": "Depth, Breadth, and Complexity: Ways to Attack and Defend Deep Learning Models",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3488932.3527278"
      ]
    },
    {
      "abstract": "Nowadays, deep learning achieves higher levels of accuracy than ever before. This evolution makes deep learning crucial for applications that care for safety, like self-driving cars and helps consumers to meet most of their expectations. Further, Deep Neural Networks (DNNs) are powerful approaches that employed to solve several issues. These issues include healthcare, advertising, marketing, computer vision, speech processing, natural language processing. The DNNs have marvelous progress in these different fields, but training such DNN models requires a lot of time, a vast amount of data and in most cases a lot of computational steps. Selling such pre-trained models is a profitable business model. But, sharing them without the owner permission is a serious threat. Unfortunately, once the models are sold, they can be easily copied and redistributed. This paper first presents a review of how digital watermarking technologies are really very helpful in the copyright protection of the DNNs. Then, a comparative study between the latest techniques is presented. Also, several optimizers are proposed to improve the accuracy against the fine-tuning attack. Finally, several experiments are performed with black-box settings using several optimizers and the results are compared with the SGD optimizer.",
      "authors": [
        "Fkirin, Alaa",
        "Attiya, Gamal",
        "El-Sayed, Ayman",
        "Shouman, Marwa A."
      ],
      "categories": null,
      "citations": 3,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1007/s11042-022-12566-z",
      "keywords": [
        "DNN",
        "Black-box",
        "Digital watermarking",
        "White-box",
        "Deep learning",
        "Copyright protection"
      ],
      "number_of_pages": 15,
      "pages": "15961-15975",
      "publication": {
        "category": "Journal",
        "cite_score": 6.1,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "1380-7501",
        "publisher": "Springer Netherlands",
        "sjr": 0.72,
        "snip": 1.182,
        "subject_areas": [
          "Hardware and Architecture",
          "Media Technology",
          "Computer Networks and Communications",
          "Software"
        ],
        "title": "Multimedia Tools and Applications"
      },
      "publication_date": "2022-05-01",
      "selected": null,
      "title": "Copyright protection of deep neural network models using digital watermarking: a comparative study",
      "urls": [
        "https://link.springer.com/content/pdf/10.1007/s11042-022-12566-z.pdf",
        "https://dl.acm.org/doi/10.1007/s11042-022-12566-z"
      ]
    },
    {
      "abstract": "Machine learning models based on Deep Neural Networks (DNNs) are increasingly deployed in a wide variety of applications, ranging from self-driving cars to COVID-19 diagnosis. To support the computational power necessary to train a DNN, cloud environments with dedicated Graphical Processing Unit (GPU) hardware support have emerged as critical infrastructure. However, there are many integrity challenges associated with outsourcing the computation to use GPU power, due to its inherent lack of safeguards to ensure computational integrity. Various approaches have been developed to address these challenges, building on trusted execution environments (TEE). Yet, no existing approach scales up to support realistic integrity-preserving DNN model training for heavy workloads (e.g., deep architectures and millions of training examples) without sustaining a significant performance hit. To mitigate the running time difference between pure TEE (i.e., full integrity) and pure GPU (i.e., no integrity) , we combine random verification of selected computation steps with systematic adjustments of DNN hyperparameters (e.g., a narrow gradient clipping range), which limits the attacker's ability to shift the model parameters arbitrarily. Experimental analysis shows that the new approach can achieve a 2X to 20X performance improvement over a pure TEE-based solution while guaranteeing an extremely high probability of integrity (e.g., 0.999) with respect to state-of-the-art DNN backdoor attacks.",
      "authors": [
        "Aref Asvadishirehjini",
        "Murat Kantarcioglu",
        "Bradley Malin"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3508398.3511503",
      "keywords": [
        "integrity preserving deep learning training",
        "deep learning",
        "trusted exexution environments",
        "intel sgx"
      ],
      "number_of_pages": 12,
      "pages": "4-15",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450392204",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the Twelfth ACM Conference on Data and Application Security and Privacy"
      },
      "publication_date": "2022-04-15",
      "selected": null,
      "title": "GINN: Fast GPU-TEE Based Integrity for Neural Network Training",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3508398.3511503"
      ]
    },
    {
      "abstract": " This paper presents a definition of what Autonomous Vehicle and their functions are, how they operate, gather data and what threats they have to encounter-with throughout their operations. As explained later in the article, we can observe that there are a handful of ways by which a self-driving vehicle can gather information about it\u2019s surrounding environment beside the sensors it is equipped with. These methods of gathering data are thoroughly explained in the article alongside their advantages and disadvantages. This article also tries to have a look at the methods an AV can overcome the computing challenges it is facing while guiding and controlling the vehicle, as well as staying in communication with other vehicles or any object that can provide useful information to the vehicle.",
      "authors": [
        "Sajad Familsamavati",
        "Pooria Yari",
        "Solmaz Salehian",
        "Rozita Salehian",
        "Mahdi Abbasi",
        "Mohammad R.Khosravi"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3508072.3508199",
      "keywords": [
        "Covid-19",
        "E-commerce",
        "Blockchain"
      ],
      "number_of_pages": 6,
      "pages": "641-646",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450387347",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "The 5th International Conference on Future Networks & Distributed Systems"
      },
      "publication_date": "2022-04-13",
      "selected": null,
      "title": "The Role of Big Data and Smart Technologies in Autonomous Vehicles",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3508072.3508199"
      ]
    },
    {
      "abstract": "The experimental results with the state-of-the-art methods demonstrate the superiority of our method.",
      "authors": [
        "Qi Liang",
        "Qiang Li",
        "Song Yang"
      ],
      "categories": null,
      "citations": 1,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1016/j.imavis.2021.104370",
      "keywords": [
        "Point cloud",
        "3D model",
        "GAN;",
        "Adversarial attack"
      ],
      "number_of_pages": 10,
      "pages": "",
      "publication": {
        "category": "Journal",
        "cite_score": 7.3,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "0262-8856",
        "publisher": "Elsevier Ltd.",
        "sjr": 0.798,
        "snip": 1.455,
        "subject_areas": [
          "Computer Vision and Pattern Recognition",
          "Signal Processing"
        ],
        "title": "Image Vision Comput."
      },
      "publication_date": "2022-04-01",
      "selected": null,
      "title": "LP-GAN: Learning perturbations based on generative adversarial networks for point cloud adversarial attacks",
      "urls": [
        "https://dl.acm.org/doi/10.1016/j.imavis.2021.104370"
      ]
    },
    {
      "abstract": "Abstract \u2014 The growth of Autonomous Vehicles (AVs) has brought out the need for secure data transfer between devices that are connected to the vehicle network. Internet of Vehicles (IoV) offers the ability to AVs in order to connect wirelessly not only to each other but to a variety of devices and entities that may use the same network. This ability for interconnection and the need for data exchange from the in-vehicle parts make the self-driving vehicle systems vulnerable to a variety of attacks that can be performed by a malicious user. This paper presents a secure architectural solution for data transfer and storage between data generated from in-vehicle components and cloud data management portal. The toolset for the data transfer includes: MQTT, LENSES.io, Apache KAFKA, MongoDB and Flask whereas, the tools and mechanisms which are used for cyber security are : KEYCLOAK, CLOUDFLARE, SNORT, NGINX and HASHING for integrity. The experiments conducted highlighted the performance of the solution regarding cyber security and revealed its potential for wider adoption.",
      "authors": [
        "Athanasios Sersemis",
        "Alexandros Papadopoulos",
        "Georgios Spanos",
        "Antonios Lalas",
        "Konstantinos Votis",
        "Dimitrios Tzovaras"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3503823.3503889",
      "keywords": [
        "NGINX",
        "KAFKA",
        "LENSES.io",
        "FLASK",
        "MongoDB",
        "KEYCLOAK",
        "MQTT",
        "CLOUDFLARE"
      ],
      "number_of_pages": 5,
      "pages": "357-361",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450395557",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the 25th Pan-Hellenic Conference on Informatics"
      },
      "publication_date": "2022-02-22",
      "selected": null,
      "title": "A Novel Cybersecurity Architecture for IoV Communication",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3503823.3503889"
      ]
    },
    {
      "abstract": "Trajectory planning for the unmanned vehicle in the complex environment has always been a challenging task. Planned trajectory with the corresponding target velocity or acceleration sequence must be collision-free guaranteed and as comfortable as possible on the premise of obeying the traffic rules and interaction with other dynamic social vehicles. To meet this requirement, this paper proposes a framework for trajectory planning based on spatio-temporal map. Due to the time layer architecture in the map, the trajectory can be generated with velocity and acceleration simultaneously, and the whole trajectory is constrained within a &#x2018;safety strip&#x2019;, resulting in an efficient and safety guaranteed trajectory. The framework is composed of three sections: rough search, fine optimization and safety strip-based collision avoidance. For rough search, we propose an improved A&#x002A; algorithm implemented in the discrete time layer to find out the suboptimal states efficiently. In fine optimization, the B-spline curve is exploited to connect the searched states into a continuous trajectory. And the optimal control points of B-spline are further grouped into several segments, forming the safety strip which is actually the distribution space of the planned trajectory. If necessary, an adjustment will be applied to keep the strip away from the collision zone, making the entire trajectory completely collision-free. Experiments on both public dataset and self-driving simulator show that the proposed framework can adapt to different kinds of complex traffic scenes well.",
      "authors": [
        "Ting Zhang",
        "Mengyin Fu",
        "Wenjie Song",
        "Yi Yang",
        "Meiling Wang"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1109/TITS.2020.3019514",
      "keywords": [],
      "number_of_pages": 14,
      "pages": "1030-1043",
      "publication": {
        "category": "Journal",
        "cite_score": 11.6,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "1524-9050",
        "publisher": "Institute of Electrical and Electronics Engineers Inc.",
        "sjr": 2.674,
        "snip": 3.544,
        "subject_areas": [
          "Computer Science Applications",
          "Automotive Engineering",
          "Mechanical Engineering"
        ],
        "title": "Trans. Intell. Transport. Sys."
      },
      "publication_date": "2022-02-01",
      "selected": null,
      "title": "Trajectory Planning Based on Spatio-Temporal Map With Collision Avoidance Guaranteed by Safety Strip",
      "urls": [
        "https://dl.acm.org/doi/10.1109/TITS.2020.3019514"
      ]
    },
    {
      "abstract": "Autonomous vehicles have received great attention in the last years, promising to impact a market worth billions. Nevertheless, the dream of fully autonomous cars has been delayed with current self-driving systems relying on complex processes coupled with supervised learning techniques. The deep reinforcement learning approach gives us newer possibilities to solve complex control tasks like the ones required by autonomous vehicles. It let the agent learn by interacting with the environment and from its mistakes. Unfortunately, RL is mainly applied in simulated environments, and transferring learning from simulations to the real world is a hard problem. In this paper, we use LIDAR data as input of a Deep Q-Network on a realistic 1/10 scale car prototype capable of performing training in real-time. The robot-driver learns how to run in race tracks by exploiting the experience gained through a mechanism of rewards that allow the agent to learn without human supervision. We provide a comparison of neural networks to find the best one for LIDAR data processing, two approaches to address the sim2real problem, and a detail of the performances of DQN in time-lap tasks for racing robots.",
      "authors": [
        "Michael Bosello",
        "Rita Tse",
        "Giovanni Pau"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1109/CCNC49033.2022.9700730",
      "keywords": [],
      "number_of_pages": 9,
      "pages": "290-298",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": null,
        "publisher": "IEEE Press",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "2022 IEEE 19th Annual Consumer Communications & Networking Conference (CCNC)"
      },
      "publication_date": "2022-01-08",
      "selected": null,
      "title": "Train in Austria, Race in Montecarlo: Generalized RL for Cross-Track F1&lt;sup&gt;tenth&lt;/sup&gt; LIDAR-Based Races",
      "urls": [
        "https://dl.acm.org/doi/10.1109/CCNC49033.2022.9700730"
      ]
    },
    {
      "abstract": "Brain-inspired research promotes the intersection and integration of brain science, computers, and other disciplines, driving a new round of scientific and technological revolution. This paper discusses the research content, features, and current status of research on brain-inspired computing and proposes a brain-inspired multibranch parallel interaction model. The feature extraction of the proposed model consists of two parallel convolutional neural networks (CNNs): the main feature extractor connected to the classifier and the auxiliary feature extractor. The latter can interact with the main feature extractor for multistage feature interaction. Additionally, four parallel branches are introduced in our CNN to learn the information on the importance of different feature map positions. Given the existing attacks on self-driving cars (in the case of shining attacks), we use the proposed model for training and detection. The experimental results show that the proposed model effectively reduces the redundant information on the feature maps, improves image classification accuracy to a certain extent, and has high learning efficiency and accuracy.",
      "authors": [
        "Wei Ou",
        "Zihan Jin",
        "Shiying Huang",
        "Danlei Du",
        "Jun Ye",
        "Wenbao Han"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1504/ijsnet.2022.127106",
      "keywords": [
        "shining attack",
        "CNNs",
        "feature extraction",
        "convolutional neural networks",
        "brain-inspired",
        "multibranch parallel interaction"
      ],
      "number_of_pages": 13,
      "pages": "203-216",
      "publication": {
        "category": "Journal",
        "cite_score": 2.3,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "1748-1279",
        "publisher": "Inderscience",
        "sjr": 0.315,
        "snip": 0.401,
        "subject_areas": [
          "Electrical and Electronic Engineering",
          "Computer Science Applications",
          "Computer Networks and Communications",
          "Control and Systems Engineering"
        ],
        "title": "Int. J. Sen. Netw."
      },
      "publication_date": "2022-01-01",
      "selected": null,
      "title": "A brain-inspired multibranch parallel interactive vision mechanism for advanced driver assistance systems",
      "urls": [
        "https://dl.acm.org/doi/10.1504/ijsnet.2022.127106"
      ]
    },
    {
      "abstract": "Robots have improved human life and increased the efficiency of performance in tasks that require precision and effort. For example, surgical robots are now used to perform precise surgical procedures and give accurate results. Moreover, robots are also used in elderly care to ease their lives. Perhaps there can even be self-driving cars that could deliver a person to their destination without the need of a driver. So it is very important to mention that these robots should be secure in terms of security for human life. Hence, this paper aims to explore the published studies on robots and their various security vulnerabilities. We review the most prominent weaknesses in the robotic operating system (ROS) and discuss some types of attacks against these robots. Also, this paper discusses the security enhancements to protect ROS that researchers have suggested protecting against some of the attacks and vulnerabilities that may occur on these robots. The primary findings of this work are to generate system copies for backup as well as encryption to protect against information disclosure. Also, a dynamic model is needed to detect and mitigate attacks that may occur in a physical manner, such as injecting malware into robots.",
      "authors": [
        "Alshamrani, Sultan S.",
        "Alkhudadi, Bdour A.",
        "Almtrafi, Sara M."
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "https://doi.org/10.1155/2022/8045874",
      "keywords": [],
      "number_of_pages": 9,
      "pages": "",
      "publication": {
        "category": "Journal",
        "cite_score": 2.6,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "1939-0114",
        "publisher": "Hindawi Limited",
        "sjr": 0.494,
        "snip": 0.785,
        "subject_areas": [
          "Information Systems",
          "Computer Networks and Communications"
        ],
        "title": "Security and Communication Networks"
      },
      "publication_date": "2022-01-01",
      "selected": null,
      "title": "Cyberattacks on Self-Driving Cars and Surgical and Eldercare Robots",
      "urls": [
        "https://downloads.hindawi.com/journals/scn/2022/8045874.pdf",
        "https://dl.acm.org/doi/10.1155/2022/8045874"
      ]
    },
    {
      "abstract": "Human trajectory prediction is an important topic in several application domains, ranging from self-driving cars to environment design and planning, from socially-aware robots to intelligent tracking systems. This complex subject comes with different challenges, such as human-space interaction, human-human interaction, multimodality, and generalizability. Currently, these challenges, especially generalizability, have not been completely explored by state-of-the-art works. This work attempts to fill this gap by proposing and defining new methods and metrics to help understand trajectories. In particular, new deep learning models based on Long Short-Term Memory and Generative Adversarial Network architectures are used in both unimodal and multimodal contexts. These approaches are evaluated with new error metrics, which normalize some biases in standard metrics. Tests have been assessed using newly collected datasets characterized by a higher diversity and lower linearity than those used in state-of-the-art works. The results prove that the proposed models and datasets are comparable to and yield better generalizability than state-of-the-art works. Moreover, we also prove that our datasets better represent multimodal scenarios (allowing for multiple possible behaviors) and that human trajectories are moderately influenced by their spatial region and slightly influenced by their date and time.",
      "authors": [
        "Luca Rossi",
        "Marina Paolanti",
        "Roberto Pierdicca",
        "Emanuele Frontoni"
      ],
      "categories": null,
      "citations": 9,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1016/j.patcog.2021.108136",
      "keywords": [
        "LSTM",
        "Trajectory generation",
        "GANs",
        "Trajectory prediction"
      ],
      "number_of_pages": 11,
      "pages": "",
      "publication": {
        "category": "Journal",
        "cite_score": 13.9,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "0031-3203",
        "publisher": "Elsevier Ltd.",
        "sjr": 2.085,
        "snip": 2.963,
        "subject_areas": [
          "Signal Processing",
          "Artificial Intelligence",
          "Computer Vision and Pattern Recognition",
          "Software"
        ],
        "title": "Pattern Recogn."
      },
      "publication_date": "2021-12-01",
      "selected": null,
      "title": "Human trajectory prediction and generation using LSTM models and GANs",
      "urls": [
        "https://dl.acm.org/doi/10.1016/j.patcog.2021.108136"
      ]
    },
    {
      "abstract": "The recent rapid progress of deep learning algorithms in generating realistic images, especially in Generative Adversarial Networks (GAN) and Variational Auto-Encoders (VAE), has helped advance new applications. Examples of such applications range from generating and manipulating new synthetic data for self-driving cars, to building/urban architectures, to interior design, and gaming. Furthermore, several applications have benefited from deep learning generative advancement, such as robotics manipulations in structured and unstructured environments, virtual fashion clothes try-on, and item identification on the go. This survey paper provides a review of techniques for image generation from background outdoor scenes, to building facades and objects, and anything in between. In particular, we will cover scene generation such as outdoor landscapes, building facades and indoor scenes. For each category, we will compare the existing state of the art algorithms and techniques, and discuss their performance and gaps limitations on a wide variety of inputs. Additionally, we will discuss challenges and future trends to advance the state of the art in realistic image generation.",
      "authors": [
        "Bouchra Bouqata",
        "Krishna Aswani",
        "David Bailey"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3485557.3485584",
      "keywords": [
        "Robotics",
        "Deep Learning",
        "Autonomous Systems",
        "Generative Adversarial Networks",
        "Synthetics Data Generation"
      ],
      "number_of_pages": 5,
      "pages": "1-5",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450384186",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "The 7th Annual International Conference on Arab Women in Computing in Conjunction with the 2nd Forum of Women in Research"
      },
      "publication_date": "2021-11-29",
      "selected": null,
      "title": "Scene Generation from Backgrounds to Objects and Anything in Between: A Deep Learning Robotics Survey",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3485557.3485584"
      ]
    },
    {
      "abstract": "Deep Learning algorithms have achieved state-of-the-art performance for Image Classification. For this reason, they have been used even in security-critical applications, such as biometric recognition systems and self-driving cars. However, recent works have shown those algorithms, which can even surpass human capabilities, are vulnerable to adversarial examples. In Computer Vision, adversarial examples are images containing subtle perturbations generated by malicious optimization algorithms to fool classifiers. As an attempt to mitigate these vulnerabilities, numerous countermeasures have been proposed recently in the literature. However, devising an efficient defense mechanism has proven to be a difficult task, since many approaches demonstrated to be ineffective against adaptive attackers. Thus, this article aims to provide all readerships with a review of the latest research progress on Adversarial Machine Learning in Image Classification, nevertheless, with a defender\u00e2\u0080\u0099s perspective. This article introduces novel taxonomies for categorizing adversarial attacks and defenses, as well as discuss possible reasons regarding the existence of adversarial examples. In addition, relevant guidance is also provided to assist researchers when devising and evaluating defenses. Finally, based on the reviewed literature, this article suggests some promising paths for future research.",
      "authors": [
        "Gabriel Resende Machado",
        "Eug\u00eanio Silva",
        "Ronaldo Ribeiro Goldschmidt"
      ],
      "categories": null,
      "citations": 26,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3485133",
      "keywords": [
        "image classification",
        "adversarial attacks",
        "defense methods",
        "adversarial images",
        "Computer vision",
        "deep neural networks"
      ],
      "number_of_pages": 38,
      "pages": "1-38",
      "publication": {
        "category": "Journal",
        "cite_score": 28.5,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "0360-0300",
        "publisher": "Association for Computing Machinery (ACM)",
        "sjr": 4.457,
        "snip": 7.155,
        "subject_areas": [
          "Theoretical Computer Science",
          "Computer Science (all)"
        ],
        "title": "ACM Comput. Surv."
      },
      "publication_date": "2021-11-23",
      "selected": null,
      "title": "Adversarial Machine Learning in Image Classification: A Survey Toward the Defender\u2019s Perspective",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3485133"
      ]
    },
    {
      "abstract": "Autonomous Vehicles (AVs), also known as self-driving cars, are becoming more prevalent in our daily lives. AVs rely on sensor information to evaluate their environment and make crucial decisions in real-time, however, new attacks can create false sensor and actuation commands. As technological advancements expand the usage of AVs to perform more complex tasks, it is imperative to secure the integrity of these devices against malicious external tampering. In this paper, we propose a security framework we call Shared Reality, which consists of verifying that sensors perceive the same physical reality. We implement our design on a custom hardware platform that uses the popular Robot Operating System (ROS) software. Our experiments show that AVs utilizing our proposed security framework ensure security with low overhead while performing several autonomous tasks.",
      "authors": [
        "Raul Quinonez",
        "Sleiman Safaoui",
        "Tyler Summers",
        "Bhavani Thuraisingham",
        "Alvaro A. Cardenas"
      ],
      "categories": null,
      "citations": 2,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3462633.3483981",
      "keywords": [
        "extended kalman filter (ekf)",
        "sensor redundancy",
        "data fusion",
        "security",
        "autonomous vehicles (avs)"
      ],
      "number_of_pages": 12,
      "pages": "15-26",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450384872",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the 2th Workshop on CPS&IoT Security and Privacy"
      },
      "publication_date": "2021-11-15",
      "selected": null,
      "title": "Shared Reality: Detecting Stealthy Attacks Against Autonomous Vehicles",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3462633.3483981"
      ]
    },
    {
      "abstract": "Deep learning accelerator is a key enabler of a variety of safety-critical applications such as self-driving car and video surveillance. However, recently reported hardware-oriented attack vectors, e.g., fault injection attacks, have extended the threats on deployed deep neural network (DNN) systems beyond the software attack boundary by input data perturbation. Existing fault mitigation schemes including data masking, zeroing-on-error and circuit level time-borrowing techniques exploit the noise-tolerance of neural network models to resist random and sparse errors. Such noise tolerant-based schemes are not sufficiently effective to suppress intensive transient errors if a DNN accelerator is blasted with malicious and deliberate faults. In this paper, we conduct comprehensive investigations on reported resilient designs and propose a more robust countermeasure to fault injection attacks. The proposed design utilizes shadow flip flops for error detection and lightweight circuit for timely error correction. Our forward error compensation scheme rectifies the incorrect partial sum of the multiply-accumulation operation by estimating the difference between the correct and error-inflicted computation. The difference is added back to the final accumulated result at a later cycle without stalling the execution pipeline. We implemented our proposed design and the existing fault-mitigation schemes on the same Intel FPGA-based DNN accelerator to demonstrate its substantially enhanced resiliency against deliberate fault attacks on two popular DNN models, ResNet50 and VGG16, trained with ImageNet.",
      "authors": [
        "Wenye Liu",
        "Chip-Hong Chang"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3474376.3487281",
      "keywords": [
        "hardware security",
        "deep neural network accelerator",
        "fault injection attack"
      ],
      "number_of_pages": 10,
      "pages": "41-50",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450386623",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the 5th Workshop on Attacks and Solutions in Hardware Security"
      },
      "publication_date": "2021-11-15",
      "selected": null,
      "title": "A Forward Error Compensation Approach for Fault Resilient Deep Neural Network Accelerator Design",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3474376.3487281"
      ]
    },
    {
      "abstract": "Edge Artificial Intelligence (AI) is a timely complement of cloud-based AI. By introducing intelligence to the edge, it alleviates privacy concerns of streaming and storing data to the cloud, enables real-time operations where milliseconds matter, and brings AI services to remote areas with poor networking infrastructures. Security is a significant problem in Edge AI applications such as self-driving cars and intelligent healthcare. Since the edge devices are empowered to process data and take actions, attacking and compromising them can cause serious damage. However, the wide deployment of computationally limited devices in edge environments and the increasing happening of side-channel (or leakage) attacks pose critical challenges to security. This article thereby aims to enhance the security for Edge AI by designing and developing lightweight and leakage-resilient authenticated key exchange (LRAKE) protocols. Compared with available LRAKE protocols, the proposed protocols in this article can be effortless applied in some mainstreaming security and communication standards. Moreover, this article realizes prototypes and presents implementation details; and a use case of applying the proposed protocol in Bluetooth 5.0 is illustrated. The theoretical design and implementation details will provide a guidance of applying the LRAKE protocols in Edge AI applications.",
      "authors": [
        "Jie Zhang",
        "Futai Zhang",
        "Xin Huang",
        "Xin Liu"
      ],
      "categories": null,
      "citations": 1,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1109/TDSC.2020.2967703",
      "keywords": [],
      "number_of_pages": 13,
      "pages": "2835-2847",
      "publication": {
        "category": "Journal",
        "cite_score": 10.4,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "1545-5971",
        "publisher": "Institute of Electrical and Electronics Engineers Inc.",
        "sjr": 1.828,
        "snip": 2.626,
        "subject_areas": [
          "Electrical and Electronic Engineering",
          "Computer Science (all)"
        ],
        "title": "IEEE Trans. Dependable Secur. Comput."
      },
      "publication_date": "2021-11-01",
      "selected": null,
      "title": "Leakage-Resilient Authenticated Key Exchange for Edge Artificial Intelligence",
      "urls": [
        "https://dl.acm.org/doi/10.1109/TDSC.2020.2967703"
      ]
    },
    {
      "abstract": "A huge number of edge applications including self-driving cars, mobile health, robotics, and augmented reality / virtual reality are enabled by deep neural networks (DNNs). Currently, much of this computation for these applications happens in the cloud, but there are several good reasons to perform the processing on local edge platforms such as smartphones: improved accessibility to different parts of the world, low latency, and data privacy. In this paper, we present a general hardware and software co-design framework for energy-efficient edge AI for both simple classification and structured output prediction tasks (e.g., 3D shapes from images). This framework relies on two key ideas. First, we design a space of DNNs of increasing complexity (coarse to fine) and perform input-specific adaptive inference by selecting a DNN of appropriate complexity depending on the hardness of input examples. Second, we execute the selected DNN on the target edge platform using a resource management policy to save energy. We also provide instantiations of our co-design framework for three qualitatively different problem settings: convolutional neural networks for image classification, graph convolutional networks for predicting 3D shapes from images, and generative adversarial networks on photo-realistic unconditional image generation. Our experiments on real-world benchmarks and mobile platforms show the effectiveness of our co-design framework in achieving significant gain in energy with little to no loss in accuracy of predictions.",
      "authors": [
        "Nitthilan Kannappan Jayakodi",
        "Janardhan Rao Doppa",
        "Partha Pratim Pande"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1109/ICCAD51958.2021.9643557",
      "keywords": [],
      "number_of_pages": 7,
      "pages": "1-7",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": null,
        "publisher": "IEEE Press",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD)"
      },
      "publication_date": "2021-11-01",
      "selected": null,
      "title": "A General Hardware and Software Co-Design Framework for Energy-Efficient Edge AI",
      "urls": [
        "https://dl.acm.org/doi/10.1109/ICCAD51958.2021.9643557"
      ]
    },
    {
      "abstract": "In this paper, we present GrandDetAuto, the first scheme to identify malicious devices efficiently within large autonomous networks of collaborating entities. GrandDetAuto functions without relying on a central trusted entity, works reliably for very large networks of devices, and is adaptable to a wide range of application scenarios thanks to interchangeable components. Our scheme uses random elections to embed integrity validation schemes in distributed consensus, providing a solution supporting tens of thousands of devices. We implemented and evaluated a concrete instance of GrandDetAuto on a network of embedded devices and conducted large-scale network simulations with up to 100\u2009000 nodes. Our results show the effectiveness and efficiency of our scheme, revealing logarithmic growth in run-time and message complexity with increasing network size. Moreover, we provide an extensive evaluation of key parameters showing that GrandDetAuto is applicable to many scenarios with diverse requirements.",
      "authors": [
        "Tigist Abera",
        "Ferdinand Brasser",
        "Lachlan Gunn",
        "Patrick Jauernig",
        "David Koisser",
        "Ahmad-Reza Sadeghi"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3471621.3471868",
      "keywords": [
        "malicious device detection",
        "security",
        "autonomous networks"
      ],
      "number_of_pages": 15,
      "pages": "220-234",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450390583",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the 24th International Symposium on Research in Attacks, Intrusions and Defenses"
      },
      "publication_date": "2021-10-07",
      "selected": null,
      "title": "GrandDetAuto: Detecting Malicious Nodes in Large-Scale Autonomous Networks",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3471621.3471868"
      ]
    },
    {
      "abstract": "Autonomous driving is one of the most challenging problems of the last decades. The development in recent years is mainly due to the continuous expansion of Artificial Intelligence. Nowadays, most self-driving systems use Deep Learning techniques. In recent years,...",
      "authors": [
        "Riboni, Alessandro",
        "Candelieri, Antonio",
        "Borrotti, Matteo"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1007/978-3-030-95467-3_16",
      "keywords": [
        "Transfer learning",
        "Autonomous driving",
        "Deep Q-learning"
      ],
      "number_of_pages": 13,
      "pages": "201-213",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": 2.2,
        "is_potentially_predatory": false,
        "isbn": "978-3-030-95466-6",
        "issn": "1611-3349",
        "publisher": "Springer Verlag",
        "sjr": 0.32,
        "snip": 0.542,
        "subject_areas": [
          "Theoretical Computer Science",
          "Computer Science (all)"
        ],
        "title": "Machine Learning, Optimization, and Data Science: 7th International Conference, LOD 2021, Grasmere, UK, October 4\u20138, 2021, Revised Selected Papers, Part I"
      },
      "publication_date": "2021-10-04",
      "selected": null,
      "title": "Deep Autonomous Agents Comparison for Self-driving Cars",
      "urls": [
        "https://link.springer.com/content/pdf/10.1007/978-3-030-95467-3_16.pdf",
        "https://dl.acm.org/doi/10.1007/978-3-030-95467-3_16"
      ]
    },
    {
      "abstract": "3D object detection is a key component of many robotic applications such as self-driving vehicles. While many approaches rely on expensive 3D sensors such as LiDAR to produce accurate 3D estimates, methods that exploit stereo cameras have recently shown promising results at a lower cost. Existing approaches tackle this problem in two steps: first depth estimation from stereo images is performed to produce a pseudo LiDAR point cloud, which is then used as input to a 3D object detector. However, this approach is suboptimal due to the representation mismatch, as the two tasks are optimized in two different metric spaces. In this paper we propose a model that unifies these two tasks and performs them in the same metric space. Specifically, we directly construct a pseudo LiDAR feature volume (PLUME) in 3D space, which is then used to solve both depth estimation and object detection tasks. Our approach achieves state-of-the-art performance with much faster inference times when compared to existing methods on the challenging KITTI benchmark [1].",
      "authors": [
        "Yan Wang",
        "Bin Yang",
        "Rui Hu",
        "Ming Liang",
        "Raquel Urtasun"
      ],
      "categories": null,
      "citations": 2,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1109/IROS51168.2021.9635875",
      "keywords": [],
      "number_of_pages": 8,
      "pages": "3383-3390",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": null,
        "publisher": "IEEE Press",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)"
      },
      "publication_date": "2021-09-27",
      "selected": null,
      "title": "PLUMENet: Efficient 3D Object Detection from Stereo Images",
      "urls": [
        "https://dl.acm.org/doi/10.1109/IROS51168.2021.9635875"
      ]
    },
    {
      "abstract": "In order to assure safety in self-driving cars, the Autonomous Drive functionality needs to pass safety tests not only based on real scenarios collected from field driving tests, but also according to similar perturbed trajectories that might have not been collected in the data collection. To achieve this goal, we need to build a scenario database containing both real-world collected data and synthesized scenarios that are consistent with the real-world driving behaviour. This requires accurate and efficient annotation methods for extraction and analysis of driving scenarios trajectories. In this study, we propose an effective non-parametric trajectory clustering framework to annotate scenarios based on transitive relations of trajectories in an embedded space. We investigate the proposed framework&#x0027;s performance on real-world trajectory data sets and demonstrate its promising results, despite the complexity caused by having trajectories of varying lengths. Furthermore, we extend the framework to validate the augmentation of the real data sets with the synthetic trajectories generated by Generative Adversarial Networks (Recurrent AE-GAN) where we conclude the consistency of the generated and the real scenarios.",
      "authors": [
        "Fazeleh Hoseini",
        "Sadegh Rahrovani",
        "Morteza Haghir Chehreghani"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1109/ITSC48978.2021.9565050",
      "keywords": [],
      "number_of_pages": 8,
      "pages": "1314-1321",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": null,
        "publisher": "IEEE Press",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "2021 IEEE International Intelligent Transportation Systems Conference (ITSC)"
      },
      "publication_date": "2021-09-19",
      "selected": null,
      "title": "Vehicle Motion Trajectories Clustering via Embedding Transitive Relations",
      "urls": [
        "https://dl.acm.org/doi/10.1109/ITSC48978.2021.9565050"
      ]
    },
    {
      "abstract": "State-of-the-art lane detection methods use a variety of deep learning techniques for lane feature extraction and prediction, demonstrating better performance than conventional lane detectors. However, deep learning approaches are computationally demanding and often fail to meet real-time requirements of autonomous vehicles. This paper proposes a lane detection method using a light-weight convolutional neural network model as a feature extractor exploiting the potential of deep learning while meeting real-time needs. The developed model is trained with a dataset containing small image patches of dimension 16 &#x00D7; 64 pixels and a non-overlapping sliding window approach is employed to achieve fast inference. Then, the predictions are clustered and fitted with a polynomial to model the lane boundaries. The proposed method was tested on the KITTI and Caltech datasets and demonstrated an acceptable performance. We also integrated the detector into the localization and planning system of our autonomous vehicle and runs at 28 fps in a CPU on image resolution of 768 &#x00D7; 1024 meeting real-time requirements needed for self-driving cars.",
      "authors": [
        "Tesfamchael Getahun",
        "Ali Karimoddini",
        "Priyantha Mudalige"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1109/ITSC48978.2021.9564965",
      "keywords": [],
      "number_of_pages": 6,
      "pages": "1527-1532",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": null,
        "publisher": "IEEE Press",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "2021 IEEE International Intelligent Transportation Systems Conference (ITSC)"
      },
      "publication_date": "2021-09-19",
      "selected": null,
      "title": "A Deep Learning Approach for Lane Detection",
      "urls": [
        "https://dl.acm.org/doi/10.1109/ITSC48978.2021.9564965"
      ]
    },
    {
      "abstract": "Increasingly, the transportation industry has moved towards automation to improve safety, fuel efficiency, and system productivity. However, the increased scrutiny that automated vehicles (AV) face over functional safety has hindered the industry&#x0027;s unbridled confidence in self-driving technologies. As AVs are cyber-physical systems, they utilize distributed control to accomplish a range of safety-critical driving tasks. The Operation Systems (OS) serve as the core of these control systems. Therefore, their designs and implementation must incorporate ways to protect AVs against what must be assumed to be inevitable cyberattacks to meet the overall AV functional safety requirements. This paper investigates the connection between functional safety and cybersecurity in the context of OS. This study finds that risks due to delays can worsen by potential cybersecurity vulnerabilities through a case example of an automated vehicle following. Furthermore, attack surfaces and cybersecurity countermeasures for protecting OSs from security breaches are addressed.",
      "authors": [
        "Kevin Zhang",
        "Aspen Olmsted"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1109/ITSC48978.2021.9564848",
      "keywords": [],
      "number_of_pages": 6,
      "pages": "976-981",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": null,
        "publisher": "IEEE Press",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "2021 IEEE International Intelligent Transportation Systems Conference (ITSC)"
      },
      "publication_date": "2021-09-19",
      "selected": null,
      "title": "Examining Autonomous Vehicle Operating Systems Vulnerabilities using a Cyber-Physical Approach",
      "urls": [
        "https://dl.acm.org/doi/10.1109/ITSC48978.2021.9564848"
      ]
    },
    {
      "abstract": "Self-driving systems execute an ensemble of different self-driving workloads on embedded systems in an end-to-end manner, subject to functional and performance requirements. To enable exploration, optimization, and end-to-end evaluation on different embedded platforms, system designers critically need a benchmark suite that enables flexible and seamless configuration of self-driving scenarios, which realistically reflects real-world self-driving workloads\u2019 unique characteristics. Existing CPU and GPU embedded benchmark suites typically (1) consider isolated applications, (2) are not sensor-driven, and (3) are unable to support emerging self-driving applications that simultaneously utilize CPUs and GPUs with stringent timing requirements. On the other hand, full-system self-driving simulators (e.g., AUTOWARE, APOLLO) focus on functional simulation, but lack the ability to evaluate the self-driving software stack on various embedded platforms. To address design needs, we present Chauffeur, the first open-source end-to-end benchmark suite for self-driving vehicles with configurable representative workloads. Chauffeur is easy to configure and run, enabling researchers to evaluate different platform configurations and explore alternative instantiations of the self-driving software pipeline. Chauffeur runs on diverse emerging platforms and exploits heterogeneous onboard resources. Our initial characterization of Chauffeur on different embedded platforms \u2013 NVIDIA Jetson TX2 and Drive PX2 \u2013 enables comparative evaluation of these GPU platforms in executing an end-to-end self-driving computational pipeline to assess the end-to-end response times on these emerging embedded platforms while also creating opportunities to create application gangs for better response times. Chauffeur enables researchers to benchmark representative self-driving workloads and flexibly compose them for different self-driving scenarios to explore end-to-end tradeoffs between design constraints, power budget, real-time performance requirements, and accuracy of applications.",
      "authors": [
        "Biswadip Maity",
        "Saehanseul Yi",
        "Dongjoo Seo",
        "Leming Cheng",
        "Sung-Soo Lim",
        "Jong-Chan Kim",
        "Bryan Donyanavard",
        "Nikil Dutt"
      ],
      "categories": null,
      "citations": 4,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3477005",
      "keywords": [
        "benchmark suite",
        "self-driving vehicles",
        "Autonomous vehicles"
      ],
      "number_of_pages": 22,
      "pages": "1-22",
      "publication": {
        "category": "Journal",
        "cite_score": 4.5,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "1539-9087",
        "publisher": "Association for Computing Machinery (ACM)",
        "sjr": 0.796,
        "snip": 1.11,
        "subject_areas": [
          "Hardware and Architecture",
          "Software"
        ],
        "title": "ACM Trans. Embed. Comput. Syst."
      },
      "publication_date": "2021-09-17",
      "selected": null,
      "title": "Chauffeur: Benchmark Suite for Design and End-to-End Analysis of Self-Driving Vehicles on Embedded Systems",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3477005"
      ]
    },
    {
      "abstract": "Machine Learning applications are acknowledged at the foundation of autonomous driving, because they are the enabling technology for most driving tasks. However, the inclusion of trained agents in automotive systems exposes the vehicle to novel attacks and faults,...",
      "authors": [
        "Piazzesi, Niccol\u00f2",
        "Hong, Massimo",
        "Ceccarelli, Andrea"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1007/978-3-030-83903-1_14",
      "keywords": [
        "Simulation",
        "Machine Learning",
        "Adversarial attacks",
        "Faults",
        "Self-driving",
        "Trained agent",
        "Injection"
      ],
      "number_of_pages": 16,
      "pages": "210-225",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": 2.2,
        "is_potentially_predatory": false,
        "isbn": "978-3-030-83902-4",
        "issn": "1611-3349",
        "publisher": "Springer Verlag",
        "sjr": 0.32,
        "snip": 0.542,
        "subject_areas": [
          "Theoretical Computer Science",
          "Computer Science (all)"
        ],
        "title": "Computer Safety, Reliability, and Security: 40th International Conference, SAFECOMP 2021, York, UK, September 8\u201310, 2021, Proceedings"
      },
      "publication_date": "2021-09-07",
      "selected": null,
      "title": "Attack and Fault Injection in Self-driving Agents on the Carla Simulator \u2013 Experience Report",
      "urls": [
        "https://dl.acm.org/doi/10.1007/978-3-030-83903-1_14",
        "https://link.springer.com/content/pdf/10.1007/978-3-030-83903-1_14.pdf"
      ]
    },
    {
      "abstract": "Autonomous systems such as self-driving cars rely on sensors to perceive the surrounding world. Measures must be taken against attacks on sensors, which have been a hot topic in the last few years. For that goal one must first evaluate how sensor attacks affect the...",
      "authors": [
        "Shimizu, Koichi",
        "Suzuki, Daisuke",
        "Muramatsu, Ryo",
        "Mori, Hisashi",
        "Nagatsuka, Tomoyuki",
        "Matsumoto, Tsutomu"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1007/978-3-030-83903-1_1",
      "keywords": [
        "Sensor attack",
        "Safety",
        "STAMP/STPA",
        "SOTIF",
        "Autonomous systems",
        "Performance limitation",
        "Security"
      ],
      "number_of_pages": 15,
      "pages": "67-81",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": 2.2,
        "is_potentially_predatory": false,
        "isbn": "978-3-030-83902-4",
        "issn": "1611-3349",
        "publisher": "Springer Verlag",
        "sjr": 0.32,
        "snip": 0.542,
        "subject_areas": [
          "Theoretical Computer Science",
          "Computer Science (all)"
        ],
        "title": "Computer Safety, Reliability, and Security: 40th International Conference, SAFECOMP 2021, York, UK, September 8\u201310, 2021, Proceedings"
      },
      "publication_date": "2021-09-07",
      "selected": null,
      "title": "Evaluation Framework for Performance Limitation of Autonomous Systems Under Sensor Attack",
      "urls": [
        "https://dl.acm.org/doi/10.1007/978-3-030-83903-1_1",
        "https://link.springer.com/content/pdf/10.1007/978-3-030-83903-1_1.pdf"
      ]
    },
    {
      "abstract": "Pedestrian trajectory prediction is crucial across a wide range of applications like self-driving vehicles and social robots. Such prediction is challenging because crowd behavior is inherently determined by various factors, such as obstacles, stationary crowd groups...",
      "authors": [
        "Huang, Binhao",
        "Ma, Zhenwei",
        "Chen, Lianggangxu",
        "He, Gaoqi"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1007/978-3-030-89029-2_15",
      "keywords": [
        "Energy map",
        "Pedestrian trajectory prediction",
        "Crowd behavior",
        "Social interaction",
        "Self-attention"
      ],
      "number_of_pages": 12,
      "pages": "190-201",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": 2.2,
        "is_potentially_predatory": false,
        "isbn": "978-3-030-89028-5",
        "issn": "1611-3349",
        "publisher": "Springer Verlag",
        "sjr": 0.32,
        "snip": 0.542,
        "subject_areas": [
          "Theoretical Computer Science",
          "Computer Science (all)"
        ],
        "title": "Advances in Computer Graphics: 38th Computer Graphics International Conference, CGI 2021, Virtual Event, September 6\u201310, 2021, Proceedings"
      },
      "publication_date": "2021-09-06",
      "selected": null,
      "title": "Social-Scene-Aware Generative Adversarial Networks for Pedestrian Trajectory Prediction",
      "urls": [
        "https://link.springer.com/content/pdf/10.1007/978-3-030-89029-2_15.pdf",
        "https://dl.acm.org/doi/10.1007/978-3-030-89029-2_15"
      ]
    },
    {
      "abstract": "We distinguish two general modes of testing for Deep Neural Networks (DNNs): Offline testing where DNNs are tested as individual units based on test datasets obtained without involving the DNNs under test, and online testing where DNNs are embedded into a specific application environment and tested in a closed-loop mode in interaction with the application environment. Typically, DNNs are subjected to both types of testing during their development life cycle where offline testing is applied immediately after DNN training and online testing follows after offline testing and once a DNN is deployed within a specific application environment. In this paper, we study the relationship between offline and online testing. Our goal is to determine how offline testing and online testing differ or complement one another and if offline testing results can be used to help reduce the cost of online testing? Though these questions are generally relevant to all autonomous systems, we study them in the context of automated driving systems where, as study subjects, we use DNNs automating end-to-end controls of steering functions of self-driving vehicles. Our results show that offline testing is less effective than online testing as many safety violations identified by online testing could not be identified by offline testing, while large prediction errors generated by offline testing always led to severe safety violations detectable by online testing. Further, we cannot exploit offline testing results to reduce the cost of online testing in practice since we are not able to identify specific situations where offline testing could be as accurate as online testing in identifying safety requirement violations.",
      "authors": [
        "Haq, Fitash Ul",
        "Shin, Donghwan",
        "Nejati, Shiva",
        "Briand, Lionel"
      ],
      "categories": null,
      "citations": 4,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1007/s10664-021-09982-4",
      "keywords": [
        "Deep Learning",
        "Testing",
        "Self-driving Cars"
      ],
      "number_of_pages": 30,
      "pages": "",
      "publication": {
        "category": "Journal",
        "cite_score": 7.9,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "1382-3256",
        "publisher": "Springer Netherlands",
        "sjr": 1.287,
        "snip": 2.382,
        "subject_areas": [
          "Software"
        ],
        "title": "Empirical Software Engineering"
      },
      "publication_date": "2021-09-01",
      "selected": null,
      "title": "Can Offline Testing of Deep Neural Networks Replace Their Online Testing?",
      "urls": [
        "https://dl.acm.org/doi/10.1007/s10664-021-09982-4",
        "https://link.springer.com/content/pdf/10.1007/s10664-021-09982-4.pdf"
      ]
    },
    {
      "abstract": " Autonomous vehicles (AV) are becoming a part of humans\u2019 everyday life. There are numerous pilot projects of driverless public buses; some car manufacturers deliver their premium-level automobiles with advanced self-driving features. Thus, assuring the security of a Passenger\u2013Autonomous Vehicle interaction arises as an important research topic, as along with opportunities, new cybersecurity risks and challenges occur that potentially may threaten Passenger\u2019s privacy and safety on the roads. This study proposes an approach of the security requirements elicitation based on the developed threat model. Thus, information security risk management helps to fulfil one of the principles needed to protect data privacy - information security. We demonstrate the process of security requirements elicitation to mitigate arising security risks. The findings of the paper are case-oriented and are based on the literature review. They are applicable for AV system implementation used by ride-hailing service providers that enable supervisory AV control.",
      "authors": [
        "Mariia Bakhtina",
        "Raimundas Matulevicius"
      ],
      "categories": null,
      "citations": 1,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3465481.3470045",
      "keywords": [
        "human-computer interaction",
        "information system security risk management (ISSRM)",
        "autonomous vehicles",
        "threat modelling"
      ],
      "number_of_pages": 10,
      "pages": "1-10",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450390514",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the 16th International Conference on Availability, Reliability and Security"
      },
      "publication_date": "2021-08-17",
      "selected": null,
      "title": "Information Security Analysis in the Passenger-Autonomous Vehicle Interaction",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3465481.3470045"
      ]
    },
    {
      "abstract": "Emerging technologies, like self-driving cars, drones, and the Internet-of-Things must not impose threats to people, neither due to accidental failures (safety), nor due to malicious attacks (security). As historically separated fields, safety and security are often...",
      "authors": [
        "Stoelinga, Marielle",
        "Kolb, Christina",
        "Nicoletti, Stefano M.",
        "Budde, Carlos E.",
        "Hahn, Ernst Moritz"
      ],
      "categories": null,
      "citations": 1,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1007/978-3-030-84629-9_1",
      "keywords": [
        "Fault trees",
        "Safety",
        "Fault tree-attack tree integration",
        "Model-based",
        "Attack trees",
        "Interaction",
        "Security"
      ],
      "number_of_pages": 19,
      "pages": "3-21",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": 2.2,
        "is_potentially_predatory": false,
        "isbn": "978-3-030-84628-2",
        "issn": "1611-3349",
        "publisher": "Springer Verlag",
        "sjr": 0.32,
        "snip": 0.542,
        "subject_areas": [
          "Theoretical Computer Science",
          "Computer Science (all)"
        ],
        "title": "Model Checking Software: 27th International Symposium, SPIN 2021, Virtual Event, July 12, 2021, Proceedings"
      },
      "publication_date": "2021-07-12",
      "selected": null,
      "title": "The Marriage Between Safety and Cybersecurity: Still Practicing",
      "urls": [
        "https://dl.acm.org/doi/10.1007/978-3-030-84629-9_1",
        "https://link.springer.com/content/pdf/10.1007/978-3-030-84629-9_1.pdf"
      ]
    },
    {
      "abstract": "This paper presents a Deep Reinforcement Learning (DRL) framework adapted and trained for Autonomous Vehicles (AVs) purposes. To do that, we propose a novel software architecture for training and validating DRL based control algorithms that exploits the concepts of standard communication in robotics using the Robot Operating System (ROS), the Docker approach to provide the system with portability, isolation and flexibility, and CARLA (CAR Learning to Act) as our hyper-realistic open-source simulation platform. First, the algorithm is introduced in the context of Self-Driving and DRL tasks. Second, we highlight the steps to merge the proposed algorithm with ROS, Docker and the CARLA simulator, as well as how the training stage is carried out to generate our own model, specifically designed for the AV paradigm. Finally, regarding our proposed validation architecture, the paper compares the trained model with other state-of-the-art traditional control approaches, demonstrating the full strength of our DL based control algorithm, as a preliminary stage before implementing it in our real-world autonomous electric car.",
      "authors": [
        "\u00d3scar P\u00e9rez-Gill",
        "Rafael Barea",
        "Elena L\u00f3pez-Guill\u00e9n",
        "Luis M. Bergasa",
        "Carlos G\u00f3mez-Hu\u00e9lamo",
        "Rodrigo Guti\u00e9rrez",
        "Alejandro D\u00edaz"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1109/IV48863.2021.9575616",
      "keywords": [],
      "number_of_pages": 6,
      "pages": "1268-1273",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": null,
        "publisher": "IEEE Press",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "2021 IEEE Intelligent Vehicles Symposium (IV)"
      },
      "publication_date": "2021-07-11",
      "selected": null,
      "title": "Deep Reinforcement Learning based control algorithms: Training and validation using the ROS Framework in CARLA Simulator for Self-Driving applications",
      "urls": [
        "https://dl.acm.org/doi/10.1109/IV48863.2021.9575616"
      ]
    },
    {
      "abstract": "Secure ranging is poised to play a critical role in several emerging applications such as self-driving cars, unmanned aerial systems, wireless IoT devices, and augmented reality. In this paper, we propose a design of a secure broadcast ranging system with unique features and techniques. Its spectral-flexibility, and low-power short ranging bursts enable co-existence with existing systems such as in the 2.4GHz ISM band. We exploit a set of RF techniques such as upsampling and successive interference cancellation to achieve high accuracy and scalability to tens of reflectors even when operating over narrow bands of spectrum. We demonstrate that it can be implemented on popular SDR platforms FPGA and/or hosts (with minimal FPGA modifications). The protocol design, and cryptographically generated/detected signals, and randomized timing of transmissions, provide stealth and security against denial of service, sniffing, and distance manipulation attacks. Through extensive experimental evaluations (and simulations for scalability to over 100 reflectors) we demonstrate an accuracy below 20cm on a wide range of SNR (as low as 0dB), spectrum 25MHz-100MHz, with bursts as short as 5us.",
      "authors": [
        "Tien Dang Vo-Huu",
        "Triet Dang Vo-Huu",
        "Guevara Noubir"
      ],
      "categories": null,
      "citations": 1,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3448300.3467819",
      "keywords": [
        "privacy",
        "software defined radio",
        "protocols",
        "wireless ranging"
      ],
      "number_of_pages": 11,
      "pages": "300-310",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450383493",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the 14th ACM Conference on Security and Privacy in Wireless and Mobile Networks"
      },
      "publication_date": "2021-06-28",
      "selected": null,
      "title": "Spectrum-flexible secure broadcast ranging",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3448300.3467819"
      ]
    },
    {
      "abstract": "Multi-task learning systems are commonly adopted in many real-world AI applications such as intelligent robots and self-driving vehicles. Instead of improving single-network performance, this work proposes a specialized Multi-Task Deep Learning Accelerator architecture, MT-DLA, to improve the performance of concurrent networks by exploiting the shared feature and parameters across these models. It is shown in our evaluation with realistic multi-task workloads, MT-DLA dramatically eliminates the memory and computation overhead caused by the shared parameters, activations and computation result. In the experiments with real-world multi-task learning workloads, MT-DLA brings about 1.4x-7.0x energy efficiency boost when compared to the baseline neural network accelerator without multi-task support.",
      "authors": [
        "Mengdi Wang",
        "Bing Li",
        "Ying Wang",
        "Cheng Liu",
        "Xiaohan Ma",
        "Xiandong Zhao",
        "Lei Zhang"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3453688.3461514",
      "keywords": [
        "deep learning accelerator",
        "coordinated compression",
        "multi-task learning"
      ],
      "number_of_pages": 8,
      "pages": "1-8",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450383936",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the 2021 on Great Lakes Symposium on VLSI"
      },
      "publication_date": "2021-06-22",
      "selected": null,
      "title": "MT-DLA: An Efficient Multi-Task Deep Learning Accelerator Design",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3453688.3461514"
      ]
    },
    {
      "abstract": "Self-driving cars over the last decade have achieved significant progress like driving millions of miles without any human intervention. However, behavioral safety in applying deep-neural-network-based (DNN based) systems for self-driving cars could not be guaranteed. Several real-world accidents involving self-driving cars have already happened, some of which have led to fatal collisions. In this paper, we present a novel and automated technique for verifying steering angle safety for self-driving cars. The technique is based on deep learning verification (DLV), which is an automated verification framework for safety of image classification neural networks. We extend DLV by leveraging neuron coverage and slack relationship to solve the judgement problem of predicted behaviors, and thus, to achieve verification of steering angle safety for self-driving cars. We evaluate our technique on the NVIDIA\u00e2\u0080\u0099s end-to-end self-driving architecture, which is a crucial ingredient in many modern self-driving cars. Experimental results show that our technique can successfully find adversarial misclassifications (i.e., incorrect steering decisions) within given regions if they exist. Therefore, we can achieve safety verification (if no misclassification is found for all DNN layers, in which case the network can be said to be stable or reliable w.r.t. steering decisions) or falsification (in which case the adversarial examples can be used to fine-tune the network).",
      "authors": [
        "Huihui Wu",
        "Deyun Lv",
        "Tengxiang Cui",
        "Gang Hou",
        "Masahiko Watanabe",
        "Weiqiang Kong"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1007/s00165-021-00539-2",
      "keywords": [
        "Steering angle",
        "Safety verification",
        "Self-driving cars",
        "Neuron coverage",
        "Slack relationship"
      ],
      "number_of_pages": 17,
      "pages": "325-341",
      "publication": {
        "category": "Journal",
        "cite_score": 3.0,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "0934-5043",
        "publisher": "Association for Computing Machinery (ACM)",
        "sjr": 0.684,
        "snip": 1.356,
        "subject_areas": [
          "Theoretical Computer Science",
          "Software"
        ],
        "title": "Form. Asp. Comput."
      },
      "publication_date": "2021-06-01",
      "selected": null,
      "title": "SDLV: Verification of Steering Angle Safety for Self-Driving Cars",
      "urls": [
        "https://dl.acm.org/doi/10.1007/s00165-021-00539-2"
      ]
    },
    {
      "abstract": "Autonomous urban driving among human-driven cars requires a holistic understanding of road rules, driver intents and driving styles. This is challenging as a short-term, single instance, driver intent of lane change may not correspond to their driving styles for a longer duration. This paper presents an interactive behavior planner which accounts for road context, short-term driver intent, and long-term driving style to infer beliefs over the latent states of surrounding vehicles. We use a specialized Partially Observable Markov Decision Process to provide risk-averse decisions. Specifically, we consider adversarial driving scenarios caused by irrational drivers to validate the robustness of our proposed interactive behavior planner in simulation as well as on a full-size self-driving car. Our experimental results show that our algorithm enables safer and more travel time-efficient autonomous driving compared to baselines even in adversarial scenarios.",
      "authors": [
        "Yuanfu Luo",
        "Malika Meghjani",
        "Qi Heng Ho",
        "David Hsu",
        "Daniela Rus"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1109/ICRA48506.2021.9561344",
      "keywords": [],
      "number_of_pages": 7,
      "pages": "5261-5267",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": null,
        "publisher": "IEEE Press",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "2021 IEEE International Conference on Robotics and Automation (ICRA)"
      },
      "publication_date": "2021-05-30",
      "selected": null,
      "title": "Interactive Planning for Autonomous Urban Driving in Adversarial Scenarios",
      "urls": [
        "https://dl.acm.org/doi/10.1109/ICRA48506.2021.9561344"
      ]
    },
    {
      "abstract": "Monocular and stereo visions are cost-effective solutions for 3D human localization in the context of self-driving cars or social robots. However, they are usually developed independently and have their respective strengths and limitations. We propose a novel unified learning framework that leverages the strengths of both monocular and stereo cues for 3D human localization. Our method jointly (i) associates humans in left- right images, (ii) deals with occluded and distant cases in stereo settings by relying on the robustness of monocular cues, and (iii) tackles the intrinsic ambiguity of monocular perspective projection by exploiting prior knowledge of the human height distribution. We specifically evaluate outliers as well as challenging instances, such as occluded and far-away pedestrians, by analyzing the entire error distribution and by estimating calibrated confidence intervals. Finally, we critically review the official KITTI 3D metrics and propose a practical 3D localization metric tailored for humans.",
      "authors": [
        "Lorenzo Bertoni",
        "Sven Kreiss",
        "Taylor Mordan",
        "Alexandre Alahi"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1109/ICRA48506.2021.9561820",
      "keywords": [],
      "number_of_pages": 7,
      "pages": "5126-5132",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": null,
        "publisher": "IEEE Press",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "2021 IEEE International Conference on Robotics and Automation (ICRA)"
      },
      "publication_date": "2021-05-30",
      "selected": null,
      "title": "MonStereo: When Monocular and Stereo Meet at the Tail of 3D Human Localization",
      "urls": [
        "https://dl.acm.org/doi/10.1109/ICRA48506.2021.9561820"
      ]
    },
    {
      "abstract": "Computing systems are becoming ever more complex, with decisions increasingly often based on deep learning components. A wide variety of applications are being developed, many of them safety-critical, such as self-driving cars and medical diagnosis. Since deep learning is unstable with respect to adversarial perturbations, there is a need for rigorous software development methodologies that encompass machine learning components. This lecture will describe progress with developing automated verification and testing techniques for deep neural networks to ensure safety and robustness of their decisions with respect to bounded input perturbations. The techniques exploit Lipschitz continuity of the networks and aim to approximate, for a given set of inputs, the reachable set of network outputs in terms of lower and upper bounds, in anytime manner, with provable guarantees. We develop novel algorithms based on feature-guided search, games, global optimisation and Bayesian methods, and evaluate them on state-of-the-art networks. The lecture will conclude with an overview of the challenges in this field.",
      "authors": [
        "Marta Kwiatkowska"
      ],
      "categories": null,
      "citations": 1,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3324884.3418901",
      "keywords": [
        "neural networks",
        "formal verification",
        "bayesian neural networks",
        "robustness"
      ],
      "number_of_pages": 3,
      "pages": "1-3",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450367684",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering"
      },
      "publication_date": "2021-01-27",
      "selected": null,
      "title": "Safety and robustness for deep learning with provable guarantees",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3324884.3418901"
      ]
    },
    {
      "abstract": "Reliably detecting attacks in a given set of inputs is of high practical relevance because of the vulnerability of neural networks to adversarial examples. These altered inputs create a security risk in applications with real-world consequences, such as self-driving cars, robotics and financial services. We propose an unsupervised method for detecting adversarial attacks in inner layers of autoencoder (AE) networks by maximizing a non-parametric measure of anomalous node activations. Previous work in this space has shown AE networks can detect anomalous images by thresholding the reconstruction error produced by the final layer. Furthermore, other detection methods rely on data augmentation or specialized training techniques which must be asserted before training time. In contrast, we use subset scanning methods from the anomalous pattern detection domain to enhance detection power without labeled examples of the noise, retraining or data augmentation methods. In addition to an anomalous \"score\" our proposed method also returns the subset of nodes within the AE network that contributed to that score. This will allow future work to pivot from detection to visualisation and explainability. Our scanning approach shows consistently higher detection power than existing detection methods across several adversarial noise models and a wide range of perturbation strengths.",
      "authors": [
        "Celia Cintas",
        "Skyler Speakman",
        "Victor Akinwande",
        "William Ogallo",
        "Komminist Weldemariam",
        "Srihari Sridharan",
        "Edward McFowland"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.5555/3491440.3491562",
      "keywords": [],
      "number_of_pages": 7,
      "pages": "876-882",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9780999241165",
        "issn": null,
        "publisher": null,
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence"
      },
      "publication_date": "2021-01-07",
      "selected": null,
      "title": "Detecting adversarial attacks via subset scanning of autoencoder activations and reconstruction error",
      "urls": [
        "https://dl.acm.org/doi/10.5555/3491440.3491562"
      ]
    },
    {
      "abstract": "In unmanned aerial vehicle (UAV) flights, power lines are considered as one of the most threatening hazards and one of the most difficult obstacles to avoid. In recent years, many vision-based techniques have been proposed to detect power lines to facilitate self-driving UAVs and automatic obstacle avoidance. However, most of the proposed methods are typically based on a common three-step approach: (i) edge detection, (ii) the Hough transform, and (iii) spurious line elimination based on power line constrains. These approaches not only are slow and inaccurate but also require a huge amount of effort in post-processing to distinguish between power lines and spurious lines. In this paper, we introduce LS-Net, a fast single-shot line-segment detector, and apply it to power line detection. The LS-Net is by design fully convolutional, and it consists of three modules: (i) a fully convolutional feature extractor, (ii) a classifier, and (iii) a line segment regressor. Due to the unavailability of large datasets with annotations of power lines, we render synthetic images of power lines using the physically based rendering approach and propose a series of effective data augmentation techniques to generate more training data. With a customized version of the VGG-16 network as the backbone, the proposed approach outperforms existing state-of-the-art approaches. In addition, the LS-Net can detect power lines in near real time. This suggests that our proposed approach has a promising role in automatic obstacle avoidance and as a valuable component of self-driving UAVs, especially for automatic autonomous power line inspection.",
      "authors": [
        "Nguyen, Van Nhan",
        "Jenssen, Robert",
        "Roverso, Davide"
      ],
      "categories": null,
      "citations": 4,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1007/s00138-020-01138-6",
      "keywords": [
        "Deep learning",
        "Power line inspection",
        "UAVs",
        "Line segment detection",
        "Power line detection"
      ],
      "number_of_pages": 16,
      "pages": "",
      "publication": {
        "category": "Journal",
        "cite_score": 5.7,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "0932-8092",
        "publisher": "Springer Verlag",
        "sjr": 0.591,
        "snip": 1.086,
        "subject_areas": [
          "Hardware and Architecture",
          "Computer Science Applications",
          "Computer Vision and Pattern Recognition",
          "Software"
        ],
        "title": "Machine Vision and Applications"
      },
      "publication_date": "2021-01-01",
      "selected": null,
      "title": "LS-Net: fast single-shot line-segment detector",
      "urls": [
        "https://link.springer.com/content/pdf/10.1007/s00138-020-01138-6.pdf",
        "https://dl.acm.org/doi/10.1007/s00138-020-01138-6"
      ]
    },
    {
      "abstract": "With the development of the automotive industry, the security of connected and autonomous vehicles (CAVs) has become a hot research field in recent years. However, previous studies mainly focus on the threats and defending mechanisms from the networking perspective,...",
      "authors": [
        "Fang, Ziyan",
        "Zhang, Weijun",
        "Li, Zongfei",
        "Tang, Huaao",
        "Han, Hao",
        "Xu, Fengyuan"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1007/978-3-030-68851-6_7",
      "keywords": [
        "Connected and autonomous vehicles",
        "Vehicle security",
        "Autonomous vehicle algorithms",
        "V2X",
        "In-vehicle network"
      ],
      "number_of_pages": 14,
      "pages": "104-117",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": 2.2,
        "is_potentially_predatory": false,
        "isbn": "978-3-030-68850-9",
        "issn": "1611-3349",
        "publisher": "Springer Verlag",
        "sjr": 0.32,
        "snip": 0.542,
        "subject_areas": [
          "Theoretical Computer Science",
          "Computer Science (all)"
        ],
        "title": "Security, Privacy, and Anonymity in Computation, Communication, and Storage: 13th International Conference, SpaCCS 2020, Nanjing, China, December 18-20, 2020, Proceedings"
      },
      "publication_date": "2020-12-18",
      "selected": null,
      "title": "Revisiting Attacks and Defenses in Connected and Autonomous Vehicles",
      "urls": [
        "https://dl.acm.org/doi/10.1007/978-3-030-68851-6_7",
        "https://link.springer.com/content/pdf/10.1007/978-3-030-68851-6_7.pdf"
      ]
    },
    {
      "abstract": "Roads have well defined geometries, topologies, and traffic rules. While this has been widely exploited in motion planning methods to produce maneuvers that obey the law, little work has been devoted to utilize these priors in perception and motion forecasting methods. In this paper we propose to incorporate these structured priors as a loss function. In contrast to imposing hard constraints, this approach allows the model to handle non-compliant maneuvers when those happen in the real world. Safe motion planning is the end goal, and thus a probabilistic characterization of the possible future developments of the scene is key to choose the plan with the lowest expected cost. Towards this goal, we design a framework that leverages REINFORCE to incorporate non-differentiable priors over sample trajectories from a probabilistic model, thus optimizing the whole distribution. We demonstrate the effectiveness of our approach on real-world self-driving datasets containing complex road topologies and multi-agent interactions. Our motion forecasts not only exhibit better precision and map understanding, but most importantly result in safer motion plans taken by our self-driving vehicle. We emphasize that despite the importance of this evaluation, it has been often overlooked by previous perception and motion forecasting works.",
      "authors": [
        "Sergio Casas",
        "Cole Gulino",
        "Simon Suo",
        "Raquel Urtasun"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1109/IROS45743.2020.9341199",
      "keywords": [],
      "number_of_pages": 8,
      "pages": "2295-2302",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": null,
        "publisher": "IEEE Press",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)"
      },
      "publication_date": "2020-10-24",
      "selected": null,
      "title": "The Importance of Prior Knowledge in Precise Multimodal Prediction",
      "urls": [
        "https://dl.acm.org/doi/10.1109/IROS45743.2020.9341199"
      ]
    },
    {
      "abstract": "Compressing massive LiDAR point clouds in real-time is critical to autonomous machines such as drones and self-driving cars. While most of the recent prior work has focused on compressing individual point cloud frames, this paper proposes a novel system that effectively compresses a sequence of point clouds. The idea to exploit both the spatial and temporal redundancies in a sequence of point cloud frames. We first identify a key frame in a point cloud sequence and spatially encode the key frame by iterative plane fitting. We then exploit the fact that consecutive point clouds have large overlaps in the physical space, and thus spatially encoded data can be (re-)used to encode the temporal stream. Temporal encoding by reusing spatial encoding data not only improves the compression rate, but also avoids redundant computations, which significantly improves the compression speed. Experiments show that our compression system achieves 40&#x00D7; to 90&#x00D7; compression rate, significantly higher than the MPEG&#x2019;s LiDAR point cloud compression standard, while retaining high end-to-end application accuracies. Meanwhile, our compression system has a compression speed that matches the point cloud generation rate by today LiDARs and out-performs existing compression systems, enabling real-time point cloud transmission.",
      "authors": [
        "Yu Feng",
        "Shaoshan Liu",
        "Yuhao Zhu"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1109/IROS45743.2020.9341071",
      "keywords": [],
      "number_of_pages": 8,
      "pages": "10766-10773",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": null,
        "publisher": "IEEE Press",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)"
      },
      "publication_date": "2020-10-24",
      "selected": null,
      "title": "Real-Time Spatio-Temporal LiDAR Point Cloud Compression",
      "urls": [
        "https://dl.acm.org/doi/10.1109/IROS45743.2020.9341071"
      ]
    },
    {
      "abstract": "Deep Neural Networks (DNNs) have been widely applied in autonomous systems such as self-driving vehicles. Recently, DNN testing has been intensively studied to automatically generate adversarial examples, which inject small-magnitude perturbations into inputs to test DNNs under extreme situations. While existing testing techniques prove to be effective, particularly for autonomous driving, they mostly focus on generating digital adversarial perturbations, e.g., changing image pixels, which may never happen in the physical world. Thus, there is a critical missing piece in the literature on autonomous driving testing: understanding and exploiting both digital and physical adversarial perturbation generation for impacting steering decisions. In this paper, we propose a systematic physical-world testing approach, namely DeepBillboard, targeting at a quite common and practical driving scenario: drive-by billboards. DeepBillboard is capable of generating a robust and resilient printable adversarial billboard test, which works under dynamic changing driving conditions including viewing angle, distance, and lighting. The objective is to maximize the possibility, degree, and duration of the steering-angle errors of an autonomous vehicle driving by our generated adversarial billboard. We have extensively evaluated the efficacy and robustness of DeepBillboard by conducting both experiments with digital perturbations and physical-world case studies. The digital experimental results show that DeepBillboard is effective for various steering models and scenes. Furthermore, the physical case studies demonstrate that DeepBillboard is sufficiently robust and resilient for generating physical-world adversarial billboard tests for real-world driving under various weather conditions, being able to mislead the average steering angle error up to 26.44 degrees. To the best of our knowledge, this is the first study demonstrating the possibility of generating realistic and continuous physical-world tests for practical autonomous driving systems; moreover, DeepBillboard can be directly generalized to a variety of other physical entities/surfaces along the curbside, e.g., a graffiti painted on a wall.",
      "authors": [
        "Husheng Zhou",
        "Wei Li",
        "Zelun Kong",
        "Junfeng Guo",
        "Yuqun Zhang",
        "Bei Yu",
        "Lingming Zhang",
        "Cong Liu"
      ],
      "categories": null,
      "citations": 83,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3377811.3380422",
      "keywords": [],
      "number_of_pages": 12,
      "pages": "347-358",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450371216",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering"
      },
      "publication_date": "2020-10-01",
      "selected": null,
      "title": "DeepBillboard: systematic physical-world testing of autonomous driving systems",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3377811.3380422"
      ]
    },
    {
      "abstract": "One of the most critical pieces of the self-driving puzzle is the task of predicting future movement of surrounding traffic actors, which allows the autonomous vehicle to safely and effectively plan its future route in a complex world. Recently, a number of algorithms have been proposed to address this important problem, spurred by a growing interest of researchers from both industry and academia. Methods based on top-down scene rasterization on one side and Generative Adversarial Networks (GANs) on the other have shown to be particularly successful, obtaining state-of-the-art accuracies on the task of traffic movement prediction. In this paper we build upon these two directions and propose a raster-based conditional GAN architecture, powered by a novel differentiable rasterizer module at the input of the conditional discriminator that maps generated trajectories into the raster space in a differentiable manner. This simplifies the task for the discriminator as trajectories that are not scene-compliant are easier to discern, and allows the gradients to flow back forcing the generator to output better, more realistic trajectories. We evaluated the proposed method on a large-scale, real-world data set, showing that it outperforms state-of-the-art GAN-based baselines.",
      "authors": [
        "Eason Wang",
        "Henggang Cui",
        "Sai Yalamanchi",
        "Mohana Moorthy",
        "Nemanja Djuric"
      ],
      "categories": null,
      "citations": 13,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3394486.3403283",
      "keywords": [
        "self-driving vehicles",
        "deep learning",
        "motion prediction",
        "autonomous driving",
        "generative adversarial networks"
      ],
      "number_of_pages": 9,
      "pages": "2340-2348",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450379984",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining"
      },
      "publication_date": "2020-08-20",
      "selected": null,
      "title": "Improving Movement Predictions of Traffic Actors in Bird's-Eye View Models using GANs and Differentiable Trajectory Rasterization",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3394486.3403283"
      ]
    },
    {
      "abstract": "Perception plays a pivotal role in autonomous driving systems, which utilizes onboard sensors like cameras and LiDARs (Light Detection and Ranging) to assess surroundings. Recent studies have demonstrated that LiDAR-based perception is vulnerable to spoofing attacks, in which adversaries spoof a fake vehicle in front of a victim self-driving car by strategically transmitting laser signals to the victim's LiDAR sensor. However, existing attacks suffer from effectiveness and generality limitations. In this work, we perform the first study to explore the general vulnerability of current LiDAR-based perception architectures and discover that the ignored occlusion patterns in LiDAR point clouds make self-driving cars vulnerable to spoofing attacks. We construct the first black-box spoofing attack based on our identified vulnerability, which universally achieves around 80% mean success rates on all target models. We perform the first defense study, proposing CARLO to mitigate LiDAR spoofing attacks. CARLO detects spoofed data by treating ignored occlusion patterns as invariant physical features, which reduces the mean attack success rate to 5.5%. Meanwhile, we take the first step towards exploring a general architecture for robust LiDAR-based perception, and propose SVF that embeds the neglected physical features into end-to-end learning. SVF further reduces the mean attack success rate to around 2.3%.",
      "authors": [
        "Jiachen Sun",
        "Yulong Cao",
        "Qi Alfred Chen",
        "Z. Morley Mao"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.5555/3489212.3489262",
      "keywords": [],
      "number_of_pages": 18,
      "pages": "877-894",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "978-1-939133-17-5",
        "issn": null,
        "publisher": "USENIX Association",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the 29th USENIX Conference on Security Symposium"
      },
      "publication_date": "2020-08-12",
      "selected": null,
      "title": "Towards robust LiDAR-based perception in autonomous driving: general black-box adversarial sensor attack and countermeasures",
      "urls": [
        "https://dl.acm.org/doi/10.5555/3489212.3489262"
      ]
    },
    {
      "abstract": "Nowadays, deep learning is becoming increasingly important in our daily life. The appearance of deep learning in many applications in life relates to prediction and classification such as self-driving, product recommendation, advertisements and healthcare. Therefore, if a deep learning model causes false predictions and misclassification, it can do great harm. This is basically a crucial issue in the deep learning model. In addition, deep learning models use large amounts of data in the training/learning phases, which contain sensitive information. Therefore, when deep learning models are used in real-world applications, it is required to protect the privacy information used in the model. In this article, we carry out a brief review of the threats and defenses methods on security issues for the deep learning models and the privacy of the data used in such models while maintaining their performance and accuracy. Finally, we discuss current challenges and future developments.",
      "authors": [
        "Ha, Trung",
        "Dang, Tran Khanh",
        "Le, Hieu",
        "Truong, Tuan Anh"
      ],
      "categories": null,
      "citations": 3,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1007/s42979-020-00254-4",
      "keywords": [
        "Defense",
        "Security in deep learning",
        "Privacy in deep learning",
        "Threat",
        "Differential privacy",
        "Gradient descent"
      ],
      "number_of_pages": 15,
      "pages": "",
      "publication": {
        "category": "Journal",
        "cite_score": 4.3,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "2661-8907",
        "publisher": "Springer",
        "sjr": 0.6,
        "snip": 1.278,
        "subject_areas": [
          "Artificial Intelligence",
          "Computer Networks and Communications",
          "Computer Science (all)",
          "Computer Science Applications",
          "Computational Theory and Mathematics",
          "Computer Graphics and Computer-Aided Design"
        ],
        "title": "SN Computer Science"
      },
      "publication_date": "2020-08-06",
      "selected": null,
      "title": "Security and Privacy Issues in Deep Learning: A Brief Review",
      "urls": [
        "https://dl.acm.org/doi/10.1007/s42979-020-00254-4",
        "https://link.springer.com/content/pdf/10.1007/s42979-020-00254-4.pdf"
      ]
    },
    {
      "abstract": "Nowadays deep neural networks have been applied widely in many applications of computer vision including medical diagnosis and self-driving cars. However, deep neural networks are threatened by adversarial examples usually in which image pixels were perturbed unnoticeable to humans but enough to fool the deep networks. Compared to 2D image adversarial examples, 3D adversarial models are less invasive in the process of attacks, and thus more realistic. There have been many research works on generating 3D adversarial examples. In this paper, we study the robustness of 3D adversarial attacks when the victim camera is placed at different viewpoints. In particular, we find a method to create 3D adversarial examples that can achieve 100% attack success rate from all viewpoints with any integer spherical coordinates. Our method is simple as we only perturb the texture space. We create 3D models with realistic textures using 3D reconstruction from multiple uncalibrated images. With the help of a differentiable renderer, we then apply gradient based optimization to compute texture perturbations based on a set of rendered images, i.e., training dataset. Our extensive experiments show that even only including 1% of all possible rendered images in training, we can still achieve 99.9% attack success rate with the trained texture perturbations. Furthermore, our thorough experiments show high transferability of the multiview robustness of our 3D adversraial attacks across various state-of-the-art deep neural network models.",
      "authors": [
        "Philip Yao",
        "Andrew So",
        "Tingting Chen",
        "Hao Ji"
      ],
      "categories": null,
      "citations": 4,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3311790.3396652",
      "keywords": [
        "multiview robustness",
        "3D adversarial examples",
        "deep neural networks"
      ],
      "number_of_pages": 7,
      "pages": "372-378",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450366892",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Practice and Experience in Advanced Research Computing"
      },
      "publication_date": "2020-07-26",
      "selected": null,
      "title": "On Multiview Robustness of 3D Adversarial Attacks",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3311790.3396652"
      ]
    },
    {
      "abstract": "With the advent of autonomous cyber-physical systems such as self-driving cars and unmanned aerial vehicles, the use of Global Positioning System (GPS) for positioning and navigation has become ubiquitous. It is well-known that GPS is vulnerable to signal spoofing attacks. There is a need to design and develop a standalone GPS receiver capable of autonomous recovery during a spoofing attack. In this work, we present SemperFi, a single antenna, standalone, GPS receiver that is capable of tracking legitimate GPS satellite signals and estimating the true location even during a spoofing attack. Unlike majority of wireless systems where data contained in the wireless signals is important, GPS relies on the time of arrival of satellite signals. This presents a unique challenge and to address this challenge, SemperFi consists of specially designed algorithms and modules based on successive interference cancellation that are capable of recovering legitimate GPS signals that are overshadowed completely by a powerful adversary. We implement our design using Soft-GNSS and evaluate its performance against a variety of GPS datasets. Our evaluations show that SemperFi can recover from a seamless takeover attack with an accuracy of 100 m and power advantage of an attacker up to 15 dB. SemperFi can also be incorporated as a pluggable module capable of generating a spoofer free GPS signal for processing on any COTS GPS receiver available today. Finally, we release the implementation of our receiver design to the community for further development.",
      "authors": [
        "Harshad Sathaye",
        "Aanjhan Ranganathan"
      ],
      "categories": null,
      "citations": 2,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3395351.3401703",
      "keywords": [],
      "number_of_pages": 3,
      "pages": "353-355",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450380065",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the 13th ACM Conference on Security and Privacy in Wireless and Mobile Networks"
      },
      "publication_date": "2020-07-21",
      "selected": null,
      "title": "SemperFi: a spoofer eliminating standalone GPS receiver",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3395351.3401703"
      ]
    },
    {
      "abstract": "In this paper, we present a visual data analytics system, called Odin, that automatically detects and recovers from drift. Odin uses adversarial autoencoders to learn the distribution of high-dimensional images. We present an unsupervised algorithm for detecting drift by comparing the distributions of the given data against that of previously seen data. When Odin detects drift, it invokes a drift recovery algorithm to deploy specialized models tailored towards the novel data points. These specialized models outperform their non-specialized counterpart on accuracy, performance, and memory footprint. Lastly, we present a model selection algorithm for picking an ensemble of best-fit specialized models to process a given input. We evaluate the efficacy and efficiency of Odin on high-resolution dashboard camera videos captured under diverse environments from the Berkeley DeepDrive dataset. We demonstrate that Odin's models deliver 6X higher throughput, 2X higher accuracy, and 6X smaller memory footprint compared to a baseline system without automated drift detection and recovery.",
      "authors": [
        "Abhijit Suprem",
        "Joy Arulraj",
        "Calton Pu",
        "Joao Ferreira"
      ],
      "categories": null,
      "citations": 5,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.14778/3407790.3407837",
      "keywords": [],
      "number_of_pages": 13,
      "pages": "2453-2465",
      "publication": {
        "category": "Journal",
        "cite_score": 5.4,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "2150-8097",
        "publisher": "Very Large Data Base Endowment Inc.",
        "sjr": 2.012,
        "snip": 1.806,
        "subject_areas": [
          "Computer Science (miscellaneous)",
          "Computer Science (all)"
        ],
        "title": "Proc. VLDB Endow."
      },
      "publication_date": "2020-07-01",
      "selected": null,
      "title": "ODIN: automated drift detection and recovery in video analytics",
      "urls": [
        "https://dl.acm.org/doi/10.14778/3407790.3407837"
      ]
    },
    {
      "abstract": "Self-driving cars leverage on semantic segmentation to understand an urban scene. However, it is costly to collect segmentation labels, thus, synthetic datasets are used to train segmentation models. Unfortunately, the synthetic to real domain shift causes these models to perform poorly. Prior works use adversarial training to align features of both synthetic and real-world images. We observe that background objects tend to be similar across domains, while foreground objects tend to have more variations. Using this insight, we propose an adaptation method that uses foreground and background cues and adapt them separately. We also propose a mask-aware gated discriminator that learns soft masks from the input foreground and background masks instead of naively performing binary masking that immediately removes information outside of the predicted masks. We evaluate our method on two different datasets and show that our method outperforms several state-of-the-art baselines, which verifies the effectiveness of our approach.",
      "authors": [
        "Yong-Xiang Lin",
        "Daniel Stanley Tan",
        "Yung-Yao Chen",
        "Ching-Chun Huang",
        "Kai-Lung Hua"
      ],
      "categories": null,
      "citations": 1,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1109/MMUL.2020.3008529",
      "keywords": [],
      "number_of_pages": 10,
      "pages": "44-53",
      "publication": {
        "category": "Journal",
        "cite_score": 5.7,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "1070-986X",
        "publisher": "IEEE Computer Society",
        "sjr": 0.849,
        "snip": 1.175,
        "subject_areas": [
          "Computer Science Applications",
          "Software",
          "Hardware and Architecture",
          "Media Technology",
          "Signal Processing"
        ],
        "title": "IEEE MultiMedia"
      },
      "publication_date": "2020-07-01",
      "selected": null,
      "title": "Domain Adaptation With Foreground/Background Cues and Gated Discriminators",
      "urls": [
        "https://dl.acm.org/doi/10.1109/MMUL.2020.3008529"
      ]
    },
    {
      "abstract": "This work aims to incorporate lateralization and modular learning at different levels of abstraction in an evolutionary machine learning system. The results of image classification tasks show that the lateralized system efficiently learns hierarchical distributions of knowledge, demonstrating performance that is similar to (or better than) other state-of-the-art deep systems as it reasons using multiple representations. Crucially, the novel system outperformed all the state-of-the-art deep models for the classification of normal and adversarial images by 0.43% -- 2.56% and 2.15% -- 25.84%, respectively. Lateralisation enabled the system to exhibit robustness beyond previous work, which advocates for the creation of data sets that enable components of objects and the objects themselves to be learned specifically or in an end-to-end manner.",
      "authors": [
        "Abubakar Siddique",
        "Will N. Browne",
        "Gina M. Grimshaw"
      ],
      "categories": null,
      "citations": 8,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1145/3377930.3390164",
      "keywords": [
        "lateralization",
        "learning classifier systems",
        "deep learning",
        "adversarial attacks",
        "modular learning"
      ],
      "number_of_pages": 9,
      "pages": "395-403",
      "publication": {
        "category": "Conference Proceedings",
        "cite_score": null,
        "is_potentially_predatory": false,
        "isbn": "9781450371285",
        "issn": null,
        "publisher": "Association for Computing Machinery",
        "sjr": null,
        "snip": null,
        "subject_areas": [],
        "title": "Proceedings of the 2020 Genetic and Evolutionary Computation Conference"
      },
      "publication_date": "2020-06-26",
      "selected": null,
      "title": "Lateralized learning for robustness against adversarial attacks in a visual classification system",
      "urls": [
        "https://dl.acm.org/doi/10.1145/3377930.3390164"
      ]
    },
    {
      "abstract": "Despite the improved accuracy of deep neural networks, the discovery of adversarial examples has raised serious safety concerns. In this paper, we study two variants of pointwise robustness, the maximum safe radius problem, which for a given input sample computes the minimum distance to an adversarial example, and the feature robustness problem, which aims to quantify the robustness of individual features to adversarial perturbations. We demonstrate that, under the assumption of Lipschitz continuity, both problems can be approximated using finite optimisation by discretising the input space, and the approximation has provable guarantees, i.e., the error is bounded. We then show that the resulting optimisation problems can be reduced to the solution of two-player turn-based games, where the first player selects features and the second perturbs the image within the feature. While the second player aims to minimise the distance to an adversarial example, depending on the optimisation objective the first player can be cooperative or competitive. We employ an anytime approach to solve the games, in the sense of approximating the value of a game by monotonically improving its upper and lower bounds. The Monte Carlo tree search algorithm is applied to compute upper bounds for both games, and the Admissible A\u204e and the Alpha-Beta Pruning algorithms are, respectively, used to compute lower bounds for the maximum safety radius and feature robustness games. When working on the upper bound of the maximum safe radius problem, our tool demonstrates competitive performance against existing adversarial example crafting algorithms. Furthermore, we show how our framework can be deployed to evaluate pointwise robustness of neural networks in safety-critical applications such as traffic sign recognition in self-driving cars.",
      "authors": [
        "Min Wu",
        "Matthew Wicker",
        "Wenjie Ruan",
        "Xiaowei Huang",
        "Marta Kwiatkowska"
      ],
      "categories": null,
      "citations": 17,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.1016/j.tcs.2019.05.046",
      "keywords": [
        "Deep neural networks",
        "Adversarial examples",
        "Two-player game",
        "Automated verification"
      ],
      "number_of_pages": 32,
      "pages": "298-329",
      "publication": {
        "category": "Journal",
        "cite_score": 2.5,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "0304-3975",
        "publisher": "Elsevier B.V.",
        "sjr": 0.59,
        "snip": 1.037,
        "subject_areas": [
          "Theoretical Computer Science",
          "Computer Science (all)"
        ],
        "title": "Theor. Comput. Sci."
      },
      "publication_date": "2020-02-06",
      "selected": null,
      "title": "A game-based approximate verification of deep neural networks with provable guarantees",
      "urls": [
        "https://dl.acm.org/doi/10.1016/j.tcs.2019.05.046"
      ]
    },
    {
      "abstract": "The expectation of spreading autonomous vehicles lies in the hope of significantly decreasing the 1,3 million death toll accidents worldwide, which are caused by human factor 90% of the time. In policies of insurance companies the reaction time of a human realizing any dangerous situation, reacting to it and putting the breaks into action is two seconds. The reaction time would be reduced by the power of AI that can process the huge amount of data coming from sensors and with the information regarding the situation could make decision much faster than men. The aim of the research is to denote several situations and possibilities that are capable of deceiving, diverting, capturing a self-driving car or even turning it against the other vehicles by influencing the decision-making of the artificial intelligence. In this paper I will discuss several situations that might be able to confuse the artificial intelligence of the autonomous vehicles or to make them come to an inadequate decision. You can see that safe decision-making depends on the teaching method of the artificial intelligence as well as the correctness of the data uploaded. The other aim of the research is to demonstrate how could work a Manchurian Artificial Intelligence in autonomous vehicles. I will introduce the idea of Manchurian artificial intelligence which can be activated by a certain event and can pose a threat to the passengers of the vehicles. If it is present in the software of several vehicles, a chain of worldwide accidents can be induced at a certain time.",
      "authors": [
        "Gabor Kiss",
        "Valentina Emilia Balas",
        "Lakhmi C. Jain"
      ],
      "categories": null,
      "citations": 0,
      "comments": null,
      "databases": [
        "ACM"
      ],
      "doi": "10.3233/JIFS-179671",
      "keywords": [
        "external manipulation",
        "Manchurian AI",
        "self-driving car",
        "autonomous vehicle"
      ],
      "number_of_pages": 5,
      "pages": "5841-5845",
      "publication": {
        "category": "Journal",
        "cite_score": 3.6,
        "is_potentially_predatory": false,
        "isbn": null,
        "issn": "1064-1246",
        "publisher": "IOS Press BV",
        "sjr": 0.372,
        "snip": 0.638,
        "subject_areas": [
          "Artificial Intelligence",
          "Engineering (all)",
          "Statistics and Probability"
        ],
        "title": "J. Intell. Fuzzy Syst."
      },
      "publication_date": "2020-01-01",
      "selected": null,
      "title": "Manchurian artificial intelligence in autonomous vehicles",
      "urls": [
        "https://dl.acm.org/doi/10.3233/JIFS-179671"
      ]
    }
  ],
  "processed_at": "2024-01-24 13:19:47",
  "publication_types": [
    "journal",
    "conference proceedings"
  ],
  "query": "(([autonomous] OR [self driving] OR [driverless] OR [unmanned] OR [automated]) AND ([vehicle*] OR [car*] OR [drone*] OR [robot*]) AND ([attack*] OR [exploit*] OR [threat*] OR [adversarial]))",
  "since": "2020-01-01",
  "until": "2024-01-02"
}